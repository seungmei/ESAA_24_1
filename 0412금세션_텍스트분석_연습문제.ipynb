{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungmei/ESAA_24_1/blob/main/0412%EA%B8%88%EC%84%B8%EC%85%98_%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%B6%84%EC%84%9D_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 아래의 데이터를 이용하여 공부한 내용을 바탕으로 문제 2개를 만들고 답하세요."
      ],
      "metadata": {
        "id": "MbDTRcUQrUS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"book\", quiet=True)\n",
        "from nltk.book import *"
      ],
      "metadata": {
        "id": "PNjdc83Bqdpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a44f835-be4e-44a3-9f0a-b67e4d0ee698"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 목록 확인\n",
        "nltk.corpus.gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9xoXfKzrbKv",
        "outputId": "dde28906-f986-4cc7-c1a0-5c0e9945feb7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 문제 1 : 위의 텍스트에서 가장 자주 등장하는 단어 상위 10개를 출력하시오."
      ],
      "metadata": {
        "id": "iNftR22-riz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 제거\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stopwords]\n",
        "\n",
        "# 빈도 분포 계산\n",
        "freq_dist = FreqDist(filtered_words)\n",
        "\n",
        "# 가장 자주 등장하는 단어 상위 10개 출력\n",
        "top_10_words = freq_dist.most_common(10)\n",
        "print(\"상위 10개의 단어:\")\n",
        "for word, frequency in top_10_words:\n",
        "    print(f\"{word}: {frequency}번\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo9kzrrqqaNc",
        "outputId": "3a749fd7-7833-4642-dfc2-8da1e34b7bd0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "상위 10개의 단어:\n",
            "ham: 337번\n",
            "lord: 211번\n",
            "haue: 175번\n",
            "king: 172번\n",
            "shall: 107번\n",
            "come: 104번\n",
            "let: 104번\n",
            "thou: 104번\n",
            "hamlet: 100번\n",
            "good: 98번\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 문제 2: 위의 텍스트에서 각 장면이 긍정적 장면인지, 부정적 장면인지 판별하시오."
      ],
      "metadata": {
        "id": "F6fES2kkrmP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim import corpora, models\n",
        "\n",
        "# 소문자 변환\n",
        "hamlet_lower = hamlet.lower()\n",
        "\n",
        "# 불용어 제거\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = word_tokenize(hamlet_lower)\n",
        "filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "\n",
        "# 단어를 토픽 모델링을 위한 딕셔너리로 변환\n",
        "dictionary = corpora.Dictionary([filtered_words])\n",
        "\n",
        "# 문서-단어 행렬 생성\n",
        "corpus = [dictionary.doc2bow(filtered_words)]\n",
        "\n",
        "# LDA 모델 훈련\n",
        "lda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)\n",
        "\n",
        "# 토픽 출력\n",
        "print(\"토픽 결과:\")\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f\"토픽 {idx}: {topic}\")"
      ],
      "metadata": {
        "id": "rqidjKSFrl-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728a19b0-b58b-4392-909b-6bd348120947"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토픽 결과:\n",
            "토픽 0: 0.000*\"ham\" + 0.000*\"lord\" + 0.000*\"haue\" + 0.000*\"king\" + 0.000*\"shall\" + 0.000*\"come\" + 0.000*\"let\" + 0.000*\"hor\" + 0.000*\"thou\" + 0.000*\"hamlet\"\n",
            "토픽 1: 0.001*\"ham\" + 0.000*\"haue\" + 0.000*\"king\" + 0.000*\"lord\" + 0.000*\"hamlet\" + 0.000*\"thou\" + 0.000*\"good\" + 0.000*\"let\" + 0.000*\"enter\" + 0.000*\"shall\"\n",
            "토픽 2: 0.000*\"ham\" + 0.000*\"lord\" + 0.000*\"king\" + 0.000*\"haue\" + 0.000*\"shall\" + 0.000*\"let\" + 0.000*\"come\" + 0.000*\"hamlet\" + 0.000*\"thy\" + 0.000*\"thou\"\n",
            "토픽 3: 0.000*\"ham\" + 0.000*\"king\" + 0.000*\"lord\" + 0.000*\"haue\" + 0.000*\"come\" + 0.000*\"shall\" + 0.000*\"thy\" + 0.000*\"good\" + 0.000*\"hor\" + 0.000*\"oh\"\n",
            "토픽 4: 0.021*\"ham\" + 0.013*\"lord\" + 0.011*\"haue\" + 0.011*\"king\" + 0.007*\"shall\" + 0.006*\"thou\" + 0.006*\"come\" + 0.006*\"let\" + 0.006*\"hamlet\" + 0.006*\"good\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "def penn_to_wn(tag):\n",
        "    \"\"\"펜 트리뱅크 태그를 WordNet 품사 태그로 변환\"\"\"\n",
        "    if tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    elif tag.startswith('V'):\n",
        "        return wn.VERB\n",
        "    return None"
      ],
      "metadata": {
        "id": "2ej_9uxTvriu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def swn_polarity(text):\n",
        "    # 감성 지수 초기화\n",
        "    sentiment = 0.0\n",
        "    tokens_count = 0\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    raw_sentences = sent_tokenize(text)\n",
        "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산\n",
        "    for raw_sentence in raw_sentences:\n",
        "        # NTLK 기반의 품사 태깅 문장 추출\n",
        "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
        "        for word , tag in tagged_sentence:\n",
        "\n",
        "            # WordNet 기반 품사 태깅과 어근 추출\n",
        "            wn_tag = penn_to_wn(tag)\n",
        "            if wn_tag not in (wn.NOUN , wn.ADJ, wn.ADV):\n",
        "                continue\n",
        "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "            if not lemma:\n",
        "                continue\n",
        "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성.\n",
        "            synsets = wn.synsets(lemma , pos=wn_tag)\n",
        "            if not synsets:\n",
        "                continue\n",
        "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
        "            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산.\n",
        "            synset = synsets[0]\n",
        "            swn_synset = swn.senti_synset(synset.name())\n",
        "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())\n",
        "            tokens_count += 1\n",
        "\n",
        "    if not tokens_count:\n",
        "        return 0\n",
        "\n",
        "    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
        "    if sentiment >= 0 :\n",
        "        return 1\n",
        "\n",
        "    return 0"
      ],
      "metadata": {
        "id": "RnupxqiZuyFx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('sentiwordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmTa3YwXwDsb",
        "outputId": "1e2ab0df-42a4-4d28-fb4b-71895495e582"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 장면의 감성 분석 및 출력\n",
        "scene_sentiments = analyze_sentiment_hamlet(hamlet)\n",
        "for i, sentiment in enumerate(scene_sentiments):\n",
        "    print(f\"장면 {i+1}: {'긍정' if sentiment == 1 else '부정'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rNorAiBvu3q",
        "outputId": "6e86166b-cc41-4ffa-db00-13357cf04c23"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "장면 1: 긍정\n",
            "장면 2: 긍정\n",
            "장면 3: 부정\n",
            "장면 4: 부정\n",
            "장면 5: 긍정\n",
            "장면 6: 긍정\n",
            "장면 7: 긍정\n",
            "장면 8: 긍정\n",
            "장면 9: 긍정\n",
            "장면 10: 부정\n",
            "장면 11: 긍정\n",
            "장면 12: 긍정\n",
            "장면 13: 긍정\n",
            "장면 14: 긍정\n",
            "장면 15: 긍정\n",
            "장면 16: 긍정\n",
            "장면 17: 긍정\n",
            "장면 18: 긍정\n",
            "장면 19: 긍정\n",
            "장면 20: 긍정\n",
            "장면 21: 긍정\n",
            "장면 22: 부정\n",
            "장면 23: 부정\n",
            "장면 24: 긍정\n",
            "장면 25: 긍정\n",
            "장면 26: 부정\n",
            "장면 27: 긍정\n",
            "장면 28: 부정\n",
            "장면 29: 부정\n",
            "장면 30: 긍정\n",
            "장면 31: 부정\n",
            "장면 32: 부정\n",
            "장면 33: 부정\n",
            "장면 34: 긍정\n",
            "장면 35: 긍정\n",
            "장면 36: 긍정\n",
            "장면 37: 긍정\n",
            "장면 38: 긍정\n",
            "장면 39: 부정\n",
            "장면 40: 부정\n",
            "장면 41: 부정\n",
            "장면 42: 부정\n",
            "장면 43: 부정\n",
            "장면 44: 긍정\n",
            "장면 45: 긍정\n",
            "장면 46: 부정\n",
            "장면 47: 긍정\n",
            "장면 48: 부정\n",
            "장면 49: 긍정\n",
            "장면 50: 긍정\n",
            "장면 51: 부정\n",
            "장면 52: 긍정\n",
            "장면 53: 부정\n",
            "장면 54: 긍정\n",
            "장면 55: 긍정\n",
            "장면 56: 부정\n",
            "장면 57: 부정\n",
            "장면 58: 긍정\n",
            "장면 59: 긍정\n",
            "장면 60: 긍정\n",
            "장면 61: 긍정\n",
            "장면 62: 긍정\n",
            "장면 63: 긍정\n",
            "장면 64: 부정\n",
            "장면 65: 긍정\n",
            "장면 66: 긍정\n",
            "장면 67: 부정\n",
            "장면 68: 긍정\n",
            "장면 69: 긍정\n",
            "장면 70: 긍정\n",
            "장면 71: 부정\n",
            "장면 72: 부정\n",
            "장면 73: 부정\n",
            "장면 74: 긍정\n",
            "장면 75: 긍정\n",
            "장면 76: 부정\n",
            "장면 77: 긍정\n",
            "장면 78: 부정\n",
            "장면 79: 긍정\n",
            "장면 80: 부정\n",
            "장면 81: 긍정\n",
            "장면 82: 긍정\n",
            "장면 83: 긍정\n",
            "장면 84: 긍정\n",
            "장면 85: 부정\n",
            "장면 86: 긍정\n",
            "장면 87: 부정\n",
            "장면 88: 부정\n",
            "장면 89: 긍정\n",
            "장면 90: 긍정\n",
            "장면 91: 부정\n",
            "장면 92: 긍정\n",
            "장면 93: 긍정\n",
            "장면 94: 긍정\n",
            "장면 95: 긍정\n",
            "장면 96: 부정\n",
            "장면 97: 긍정\n",
            "장면 98: 부정\n",
            "장면 99: 긍정\n",
            "장면 100: 긍정\n",
            "장면 101: 긍정\n",
            "장면 102: 긍정\n",
            "장면 103: 긍정\n",
            "장면 104: 부정\n",
            "장면 105: 부정\n",
            "장면 106: 부정\n",
            "장면 107: 부정\n",
            "장면 108: 긍정\n",
            "장면 109: 긍정\n",
            "장면 110: 부정\n",
            "장면 111: 긍정\n",
            "장면 112: 부정\n",
            "장면 113: 긍정\n",
            "장면 114: 긍정\n",
            "장면 115: 긍정\n",
            "장면 116: 부정\n",
            "장면 117: 긍정\n",
            "장면 118: 긍정\n",
            "장면 119: 부정\n",
            "장면 120: 부정\n",
            "장면 121: 부정\n",
            "장면 122: 긍정\n",
            "장면 123: 부정\n",
            "장면 124: 부정\n",
            "장면 125: 긍정\n",
            "장면 126: 부정\n",
            "장면 127: 부정\n",
            "장면 128: 부정\n",
            "장면 129: 긍정\n",
            "장면 130: 부정\n",
            "장면 131: 긍정\n",
            "장면 132: 긍정\n",
            "장면 133: 긍정\n",
            "장면 134: 긍정\n",
            "장면 135: 긍정\n",
            "장면 136: 긍정\n",
            "장면 137: 긍정\n",
            "장면 138: 긍정\n",
            "장면 139: 부정\n",
            "장면 140: 부정\n",
            "장면 141: 긍정\n",
            "장면 142: 부정\n",
            "장면 143: 긍정\n",
            "장면 144: 부정\n",
            "장면 145: 긍정\n",
            "장면 146: 부정\n",
            "장면 147: 긍정\n",
            "장면 148: 긍정\n",
            "장면 149: 긍정\n",
            "장면 150: 긍정\n",
            "장면 151: 부정\n",
            "장면 152: 긍정\n",
            "장면 153: 긍정\n",
            "장면 154: 부정\n",
            "장면 155: 긍정\n",
            "장면 156: 긍정\n",
            "장면 157: 긍정\n",
            "장면 158: 부정\n",
            "장면 159: 부정\n",
            "장면 160: 부정\n",
            "장면 161: 부정\n",
            "장면 162: 부정\n",
            "장면 163: 부정\n",
            "장면 164: 긍정\n",
            "장면 165: 부정\n",
            "장면 166: 부정\n",
            "장면 167: 긍정\n",
            "장면 168: 부정\n",
            "장면 169: 부정\n",
            "장면 170: 긍정\n",
            "장면 171: 부정\n",
            "장면 172: 부정\n",
            "장면 173: 부정\n",
            "장면 174: 긍정\n",
            "장면 175: 긍정\n",
            "장면 176: 부정\n",
            "장면 177: 긍정\n",
            "장면 178: 긍정\n",
            "장면 179: 긍정\n",
            "장면 180: 부정\n",
            "장면 181: 긍정\n",
            "장면 182: 긍정\n",
            "장면 183: 부정\n",
            "장면 184: 긍정\n",
            "장면 185: 긍정\n",
            "장면 186: 긍정\n",
            "장면 187: 부정\n",
            "장면 188: 긍정\n",
            "장면 189: 부정\n",
            "장면 190: 긍정\n",
            "장면 191: 긍정\n",
            "장면 192: 부정\n",
            "장면 193: 긍정\n",
            "장면 194: 긍정\n",
            "장면 195: 긍정\n",
            "장면 196: 긍정\n",
            "장면 197: 긍정\n",
            "장면 198: 부정\n",
            "장면 199: 긍정\n",
            "장면 200: 부정\n",
            "장면 201: 긍정\n",
            "장면 202: 긍정\n",
            "장면 203: 긍정\n",
            "장면 204: 긍정\n",
            "장면 205: 긍정\n",
            "장면 206: 긍정\n",
            "장면 207: 긍정\n",
            "장면 208: 긍정\n",
            "장면 209: 긍정\n",
            "장면 210: 부정\n",
            "장면 211: 부정\n",
            "장면 212: 부정\n",
            "장면 213: 긍정\n",
            "장면 214: 긍정\n",
            "장면 215: 긍정\n",
            "장면 216: 긍정\n",
            "장면 217: 부정\n",
            "장면 218: 긍정\n",
            "장면 219: 긍정\n",
            "장면 220: 부정\n",
            "장면 221: 긍정\n",
            "장면 222: 부정\n",
            "장면 223: 긍정\n",
            "장면 224: 부정\n",
            "장면 225: 긍정\n",
            "장면 226: 긍정\n",
            "장면 227: 부정\n",
            "장면 228: 긍정\n",
            "장면 229: 부정\n",
            "장면 230: 부정\n",
            "장면 231: 부정\n",
            "장면 232: 부정\n",
            "장면 233: 긍정\n",
            "장면 234: 긍정\n",
            "장면 235: 긍정\n",
            "장면 236: 긍정\n",
            "장면 237: 긍정\n",
            "장면 238: 부정\n",
            "장면 239: 긍정\n",
            "장면 240: 부정\n",
            "장면 241: 긍정\n",
            "장면 242: 부정\n",
            "장면 243: 긍정\n",
            "장면 244: 긍정\n",
            "장면 245: 부정\n",
            "장면 246: 긍정\n",
            "장면 247: 긍정\n",
            "장면 248: 부정\n",
            "장면 249: 긍정\n",
            "장면 250: 긍정\n",
            "장면 251: 긍정\n",
            "장면 252: 긍정\n",
            "장면 253: 부정\n",
            "장면 254: 긍정\n",
            "장면 255: 부정\n",
            "장면 256: 부정\n",
            "장면 257: 부정\n",
            "장면 258: 긍정\n",
            "장면 259: 부정\n",
            "장면 260: 긍정\n",
            "장면 261: 긍정\n",
            "장면 262: 부정\n",
            "장면 263: 부정\n",
            "장면 264: 긍정\n",
            "장면 265: 부정\n",
            "장면 266: 부정\n",
            "장면 267: 부정\n",
            "장면 268: 긍정\n",
            "장면 269: 부정\n",
            "장면 270: 부정\n",
            "장면 271: 긍정\n",
            "장면 272: 긍정\n",
            "장면 273: 긍정\n",
            "장면 274: 긍정\n",
            "장면 275: 긍정\n",
            "장면 276: 긍정\n",
            "장면 277: 긍정\n",
            "장면 278: 긍정\n",
            "장면 279: 부정\n",
            "장면 280: 긍정\n",
            "장면 281: 긍정\n",
            "장면 282: 긍정\n",
            "장면 283: 긍정\n",
            "장면 284: 부정\n",
            "장면 285: 긍정\n",
            "장면 286: 긍정\n",
            "장면 287: 긍정\n",
            "장면 288: 긍정\n",
            "장면 289: 긍정\n",
            "장면 290: 긍정\n",
            "장면 291: 부정\n",
            "장면 292: 긍정\n",
            "장면 293: 부정\n",
            "장면 294: 긍정\n",
            "장면 295: 긍정\n",
            "장면 296: 긍정\n",
            "장면 297: 부정\n",
            "장면 298: 긍정\n",
            "장면 299: 부정\n",
            "장면 300: 부정\n",
            "장면 301: 긍정\n",
            "장면 302: 긍정\n",
            "장면 303: 긍정\n",
            "장면 304: 부정\n",
            "장면 305: 긍정\n",
            "장면 306: 긍정\n",
            "장면 307: 긍정\n",
            "장면 308: 부정\n",
            "장면 309: 부정\n",
            "장면 310: 긍정\n",
            "장면 311: 부정\n",
            "장면 312: 긍정\n",
            "장면 313: 긍정\n",
            "장면 314: 부정\n",
            "장면 315: 긍정\n",
            "장면 316: 긍정\n",
            "장면 317: 긍정\n",
            "장면 318: 긍정\n",
            "장면 319: 긍정\n",
            "장면 320: 부정\n",
            "장면 321: 긍정\n",
            "장면 322: 긍정\n",
            "장면 323: 부정\n",
            "장면 324: 긍정\n",
            "장면 325: 긍정\n",
            "장면 326: 부정\n",
            "장면 327: 부정\n",
            "장면 328: 긍정\n",
            "장면 329: 긍정\n",
            "장면 330: 부정\n",
            "장면 331: 긍정\n",
            "장면 332: 긍정\n",
            "장면 333: 긍정\n",
            "장면 334: 부정\n",
            "장면 335: 부정\n",
            "장면 336: 부정\n",
            "장면 337: 긍정\n",
            "장면 338: 긍정\n",
            "장면 339: 부정\n",
            "장면 340: 긍정\n",
            "장면 341: 부정\n",
            "장면 342: 긍정\n",
            "장면 343: 부정\n",
            "장면 344: 긍정\n",
            "장면 345: 긍정\n",
            "장면 346: 부정\n",
            "장면 347: 부정\n",
            "장면 348: 부정\n",
            "장면 349: 긍정\n",
            "장면 350: 긍정\n",
            "장면 351: 부정\n",
            "장면 352: 부정\n",
            "장면 353: 긍정\n",
            "장면 354: 긍정\n",
            "장면 355: 긍정\n",
            "장면 356: 긍정\n",
            "장면 357: 긍정\n",
            "장면 358: 부정\n",
            "장면 359: 긍정\n",
            "장면 360: 긍정\n",
            "장면 361: 긍정\n",
            "장면 362: 긍정\n",
            "장면 363: 긍정\n",
            "장면 364: 긍정\n",
            "장면 365: 부정\n",
            "장면 366: 긍정\n",
            "장면 367: 부정\n",
            "장면 368: 긍정\n",
            "장면 369: 부정\n",
            "장면 370: 긍정\n",
            "장면 371: 긍정\n",
            "장면 372: 부정\n",
            "장면 373: 긍정\n",
            "장면 374: 부정\n",
            "장면 375: 부정\n",
            "장면 376: 긍정\n",
            "장면 377: 긍정\n",
            "장면 378: 긍정\n",
            "장면 379: 부정\n",
            "장면 380: 부정\n",
            "장면 381: 긍정\n",
            "장면 382: 긍정\n",
            "장면 383: 긍정\n",
            "장면 384: 긍정\n",
            "장면 385: 긍정\n",
            "장면 386: 긍정\n",
            "장면 387: 부정\n",
            "장면 388: 긍정\n",
            "장면 389: 부정\n",
            "장면 390: 긍정\n",
            "장면 391: 부정\n",
            "장면 392: 긍정\n",
            "장면 393: 긍정\n",
            "장면 394: 부정\n",
            "장면 395: 긍정\n",
            "장면 396: 긍정\n",
            "장면 397: 긍정\n",
            "장면 398: 부정\n",
            "장면 399: 부정\n",
            "장면 400: 긍정\n",
            "장면 401: 긍정\n",
            "장면 402: 긍정\n",
            "장면 403: 긍정\n",
            "장면 404: 부정\n",
            "장면 405: 부정\n",
            "장면 406: 긍정\n",
            "장면 407: 긍정\n",
            "장면 408: 긍정\n",
            "장면 409: 부정\n",
            "장면 410: 부정\n",
            "장면 411: 긍정\n",
            "장면 412: 부정\n",
            "장면 413: 긍정\n",
            "장면 414: 부정\n",
            "장면 415: 긍정\n",
            "장면 416: 긍정\n",
            "장면 417: 긍정\n",
            "장면 418: 긍정\n",
            "장면 419: 부정\n",
            "장면 420: 긍정\n",
            "장면 421: 부정\n",
            "장면 422: 긍정\n",
            "장면 423: 긍정\n",
            "장면 424: 긍정\n",
            "장면 425: 긍정\n",
            "장면 426: 부정\n",
            "장면 427: 긍정\n",
            "장면 428: 긍정\n",
            "장면 429: 긍정\n",
            "장면 430: 부정\n",
            "장면 431: 부정\n",
            "장면 432: 부정\n",
            "장면 433: 부정\n",
            "장면 434: 긍정\n",
            "장면 435: 부정\n",
            "장면 436: 긍정\n",
            "장면 437: 긍정\n",
            "장면 438: 긍정\n",
            "장면 439: 긍정\n",
            "장면 440: 긍정\n",
            "장면 441: 부정\n",
            "장면 442: 부정\n",
            "장면 443: 긍정\n",
            "장면 444: 긍정\n",
            "장면 445: 긍정\n",
            "장면 446: 부정\n",
            "장면 447: 부정\n",
            "장면 448: 긍정\n",
            "장면 449: 긍정\n",
            "장면 450: 긍정\n",
            "장면 451: 부정\n",
            "장면 452: 부정\n",
            "장면 453: 부정\n",
            "장면 454: 긍정\n",
            "장면 455: 부정\n",
            "장면 456: 긍정\n",
            "장면 457: 긍정\n",
            "장면 458: 긍정\n",
            "장면 459: 긍정\n",
            "장면 460: 긍정\n",
            "장면 461: 긍정\n",
            "장면 462: 긍정\n",
            "장면 463: 부정\n",
            "장면 464: 긍정\n",
            "장면 465: 긍정\n",
            "장면 466: 긍정\n",
            "장면 467: 부정\n",
            "장면 468: 부정\n",
            "장면 469: 긍정\n",
            "장면 470: 부정\n",
            "장면 471: 부정\n",
            "장면 472: 긍정\n",
            "장면 473: 부정\n",
            "장면 474: 부정\n",
            "장면 475: 긍정\n",
            "장면 476: 긍정\n",
            "장면 477: 긍정\n",
            "장면 478: 긍정\n",
            "장면 479: 긍정\n",
            "장면 480: 부정\n",
            "장면 481: 긍정\n",
            "장면 482: 부정\n",
            "장면 483: 부정\n",
            "장면 484: 부정\n",
            "장면 485: 부정\n",
            "장면 486: 긍정\n",
            "장면 487: 부정\n",
            "장면 488: 부정\n",
            "장면 489: 부정\n",
            "장면 490: 부정\n",
            "장면 491: 긍정\n",
            "장면 492: 긍정\n",
            "장면 493: 긍정\n",
            "장면 494: 부정\n",
            "장면 495: 부정\n",
            "장면 496: 긍정\n",
            "장면 497: 긍정\n",
            "장면 498: 긍정\n",
            "장면 499: 긍정\n",
            "장면 500: 긍정\n",
            "장면 501: 부정\n",
            "장면 502: 부정\n",
            "장면 503: 부정\n",
            "장면 504: 부정\n",
            "장면 505: 부정\n",
            "장면 506: 긍정\n",
            "장면 507: 부정\n",
            "장면 508: 긍정\n",
            "장면 509: 긍정\n",
            "장면 510: 긍정\n",
            "장면 511: 부정\n",
            "장면 512: 긍정\n",
            "장면 513: 부정\n",
            "장면 514: 긍정\n",
            "장면 515: 긍정\n",
            "장면 516: 긍정\n",
            "장면 517: 긍정\n",
            "장면 518: 긍정\n",
            "장면 519: 부정\n",
            "장면 520: 긍정\n",
            "장면 521: 긍정\n",
            "장면 522: 긍정\n",
            "장면 523: 부정\n",
            "장면 524: 긍정\n",
            "장면 525: 긍정\n",
            "장면 526: 긍정\n",
            "장면 527: 긍정\n",
            "장면 528: 부정\n",
            "장면 529: 긍정\n",
            "장면 530: 부정\n",
            "장면 531: 부정\n",
            "장면 532: 긍정\n",
            "장면 533: 긍정\n",
            "장면 534: 긍정\n",
            "장면 535: 부정\n",
            "장면 536: 부정\n",
            "장면 537: 긍정\n",
            "장면 538: 긍정\n",
            "장면 539: 긍정\n",
            "장면 540: 긍정\n",
            "장면 541: 부정\n",
            "장면 542: 긍정\n",
            "장면 543: 부정\n",
            "장면 544: 긍정\n",
            "장면 545: 긍정\n",
            "장면 546: 긍정\n",
            "장면 547: 부정\n",
            "장면 548: 긍정\n",
            "장면 549: 부정\n",
            "장면 550: 긍정\n",
            "장면 551: 긍정\n",
            "장면 552: 긍정\n",
            "장면 553: 긍정\n",
            "장면 554: 긍정\n",
            "장면 555: 긍정\n",
            "장면 556: 긍정\n",
            "장면 557: 부정\n",
            "장면 558: 부정\n",
            "장면 559: 긍정\n",
            "장면 560: 부정\n",
            "장면 561: 부정\n",
            "장면 562: 긍정\n",
            "장면 563: 부정\n",
            "장면 564: 부정\n",
            "장면 565: 긍정\n",
            "장면 566: 부정\n",
            "장면 567: 부정\n",
            "장면 568: 긍정\n",
            "장면 569: 부정\n",
            "장면 570: 긍정\n",
            "장면 571: 긍정\n",
            "장면 572: 부정\n",
            "장면 573: 긍정\n",
            "장면 574: 긍정\n",
            "장면 575: 부정\n",
            "장면 576: 부정\n",
            "장면 577: 부정\n",
            "장면 578: 부정\n",
            "장면 579: 부정\n",
            "장면 580: 긍정\n",
            "장면 581: 부정\n",
            "장면 582: 긍정\n",
            "장면 583: 부정\n",
            "장면 584: 부정\n",
            "장면 585: 긍정\n",
            "장면 586: 긍정\n",
            "장면 587: 긍정\n",
            "장면 588: 부정\n",
            "장면 589: 부정\n",
            "장면 590: 부정\n",
            "장면 591: 긍정\n",
            "장면 592: 긍정\n",
            "장면 593: 긍정\n",
            "장면 594: 긍정\n",
            "장면 595: 긍정\n",
            "장면 596: 부정\n",
            "장면 597: 부정\n",
            "장면 598: 긍정\n",
            "장면 599: 긍정\n",
            "장면 600: 긍정\n",
            "장면 601: 긍정\n",
            "장면 602: 부정\n",
            "장면 603: 부정\n",
            "장면 604: 부정\n",
            "장면 605: 긍정\n",
            "장면 606: 긍정\n",
            "장면 607: 긍정\n",
            "장면 608: 긍정\n",
            "장면 609: 긍정\n",
            "장면 610: 긍정\n",
            "장면 611: 긍정\n",
            "장면 612: 긍정\n",
            "장면 613: 부정\n",
            "장면 614: 긍정\n",
            "장면 615: 부정\n",
            "장면 616: 긍정\n",
            "장면 617: 긍정\n",
            "장면 618: 긍정\n",
            "장면 619: 긍정\n",
            "장면 620: 부정\n",
            "장면 621: 긍정\n",
            "장면 622: 부정\n",
            "장면 623: 부정\n",
            "장면 624: 긍정\n",
            "장면 625: 부정\n",
            "장면 626: 긍정\n",
            "장면 627: 긍정\n",
            "장면 628: 부정\n",
            "장면 629: 부정\n",
            "장면 630: 긍정\n",
            "장면 631: 부정\n",
            "장면 632: 부정\n",
            "장면 633: 긍정\n",
            "장면 634: 긍정\n",
            "장면 635: 긍정\n",
            "장면 636: 긍정\n",
            "장면 637: 부정\n",
            "장면 638: 긍정\n",
            "장면 639: 긍정\n",
            "장면 640: 부정\n",
            "장면 641: 긍정\n",
            "장면 642: 긍정\n",
            "장면 643: 긍정\n",
            "장면 644: 긍정\n",
            "장면 645: 긍정\n",
            "장면 646: 긍정\n",
            "장면 647: 긍정\n",
            "장면 648: 긍정\n",
            "장면 649: 긍정\n",
            "장면 650: 긍정\n",
            "장면 651: 긍정\n",
            "장면 652: 긍정\n",
            "장면 653: 부정\n",
            "장면 654: 긍정\n",
            "장면 655: 긍정\n",
            "장면 656: 긍정\n",
            "장면 657: 부정\n",
            "장면 658: 부정\n",
            "장면 659: 긍정\n",
            "장면 660: 긍정\n",
            "장면 661: 긍정\n",
            "장면 662: 긍정\n",
            "장면 663: 부정\n",
            "장면 664: 부정\n",
            "장면 665: 부정\n",
            "장면 666: 긍정\n",
            "장면 667: 긍정\n",
            "장면 668: 부정\n",
            "장면 669: 부정\n",
            "장면 670: 부정\n",
            "장면 671: 긍정\n",
            "장면 672: 긍정\n",
            "장면 673: 부정\n",
            "장면 674: 부정\n",
            "장면 675: 부정\n",
            "장면 676: 긍정\n",
            "장면 677: 긍정\n",
            "장면 678: 부정\n",
            "장면 679: 부정\n",
            "장면 680: 긍정\n",
            "장면 681: 긍정\n",
            "장면 682: 긍정\n",
            "장면 683: 부정\n",
            "장면 684: 부정\n",
            "장면 685: 긍정\n",
            "장면 686: 긍정\n",
            "장면 687: 긍정\n",
            "장면 688: 부정\n",
            "장면 689: 부정\n",
            "장면 690: 부정\n",
            "장면 691: 부정\n",
            "장면 692: 부정\n",
            "장면 693: 부정\n",
            "장면 694: 부정\n",
            "장면 695: 긍정\n",
            "장면 696: 긍정\n",
            "장면 697: 긍정\n",
            "장면 698: 긍정\n",
            "장면 699: 긍정\n",
            "장면 700: 긍정\n",
            "장면 701: 부정\n",
            "장면 702: 긍정\n",
            "장면 703: 긍정\n",
            "장면 704: 부정\n",
            "장면 705: 부정\n",
            "장면 706: 부정\n",
            "장면 707: 긍정\n",
            "장면 708: 긍정\n",
            "장면 709: 긍정\n",
            "장면 710: 부정\n",
            "장면 711: 부정\n",
            "장면 712: 부정\n",
            "장면 713: 긍정\n",
            "장면 714: 부정\n",
            "장면 715: 긍정\n",
            "장면 716: 부정\n",
            "장면 717: 긍정\n",
            "장면 718: 긍정\n",
            "장면 719: 부정\n",
            "장면 720: 긍정\n",
            "장면 721: 부정\n",
            "장면 722: 긍정\n",
            "장면 723: 긍정\n",
            "장면 724: 긍정\n",
            "장면 725: 긍정\n",
            "장면 726: 긍정\n",
            "장면 727: 부정\n",
            "장면 728: 긍정\n",
            "장면 729: 부정\n",
            "장면 730: 긍정\n",
            "장면 731: 부정\n",
            "장면 732: 긍정\n",
            "장면 733: 긍정\n",
            "장면 734: 긍정\n",
            "장면 735: 부정\n",
            "장면 736: 부정\n",
            "장면 737: 긍정\n",
            "장면 738: 긍정\n",
            "장면 739: 긍정\n",
            "장면 740: 긍정\n",
            "장면 741: 긍정\n",
            "장면 742: 부정\n",
            "장면 743: 긍정\n",
            "장면 744: 긍정\n",
            "장면 745: 부정\n",
            "장면 746: 부정\n",
            "장면 747: 부정\n",
            "장면 748: 긍정\n",
            "장면 749: 긍정\n",
            "장면 750: 부정\n",
            "장면 751: 부정\n",
            "장면 752: 부정\n",
            "장면 753: 부정\n",
            "장면 754: 부정\n",
            "장면 755: 부정\n",
            "장면 756: 부정\n",
            "장면 757: 부정\n",
            "장면 758: 부정\n",
            "장면 759: 부정\n",
            "장면 760: 긍정\n",
            "장면 761: 부정\n",
            "장면 762: 부정\n",
            "장면 763: 부정\n",
            "장면 764: 부정\n",
            "장면 765: 긍정\n",
            "장면 766: 부정\n",
            "장면 767: 부정\n",
            "장면 768: 부정\n",
            "장면 769: 부정\n",
            "장면 770: 부정\n",
            "장면 771: 부정\n",
            "장면 772: 긍정\n",
            "장면 773: 긍정\n",
            "장면 774: 긍정\n",
            "장면 775: 부정\n",
            "장면 776: 부정\n",
            "장면 777: 긍정\n",
            "장면 778: 긍정\n",
            "장면 779: 긍정\n",
            "장면 780: 부정\n",
            "장면 781: 부정\n",
            "장면 782: 긍정\n",
            "장면 783: 긍정\n",
            "장면 784: 부정\n",
            "장면 785: 부정\n",
            "장면 786: 긍정\n",
            "장면 787: 긍정\n",
            "장면 788: 긍정\n",
            "장면 789: 부정\n",
            "장면 790: 부정\n",
            "장면 791: 부정\n",
            "장면 792: 부정\n",
            "장면 793: 부정\n",
            "장면 794: 긍정\n",
            "장면 795: 긍정\n",
            "장면 796: 긍정\n",
            "장면 797: 부정\n",
            "장면 798: 부정\n",
            "장면 799: 부정\n",
            "장면 800: 부정\n",
            "장면 801: 긍정\n",
            "장면 802: 부정\n",
            "장면 803: 긍정\n",
            "장면 804: 긍정\n",
            "장면 805: 긍정\n",
            "장면 806: 부정\n",
            "장면 807: 긍정\n",
            "장면 808: 부정\n",
            "장면 809: 긍정\n",
            "장면 810: 긍정\n",
            "장면 811: 부정\n",
            "장면 812: 부정\n",
            "장면 813: 부정\n",
            "장면 814: 부정\n",
            "장면 815: 긍정\n",
            "장면 816: 부정\n",
            "장면 817: 긍정\n",
            "장면 818: 부정\n",
            "장면 819: 부정\n",
            "장면 820: 긍정\n",
            "장면 821: 긍정\n",
            "장면 822: 긍정\n",
            "장면 823: 긍정\n",
            "장면 824: 긍정\n",
            "장면 825: 긍정\n",
            "장면 826: 부정\n",
            "장면 827: 부정\n",
            "장면 828: 긍정\n",
            "장면 829: 부정\n",
            "장면 830: 긍정\n",
            "장면 831: 부정\n",
            "장면 832: 부정\n",
            "장면 833: 긍정\n",
            "장면 834: 긍정\n",
            "장면 835: 긍정\n",
            "장면 836: 긍정\n",
            "장면 837: 부정\n",
            "장면 838: 부정\n",
            "장면 839: 긍정\n",
            "장면 840: 부정\n",
            "장면 841: 부정\n",
            "장면 842: 긍정\n",
            "장면 843: 긍정\n",
            "장면 844: 긍정\n",
            "장면 845: 긍정\n",
            "장면 846: 긍정\n",
            "장면 847: 긍정\n",
            "장면 848: 긍정\n",
            "장면 849: 긍정\n",
            "장면 850: 긍정\n",
            "장면 851: 부정\n",
            "장면 852: 부정\n",
            "장면 853: 긍정\n",
            "장면 854: 부정\n",
            "장면 855: 긍정\n",
            "장면 856: 긍정\n",
            "장면 857: 긍정\n",
            "장면 858: 긍정\n",
            "장면 859: 부정\n",
            "장면 860: 긍정\n",
            "장면 861: 부정\n",
            "장면 862: 부정\n",
            "장면 863: 부정\n",
            "장면 864: 긍정\n",
            "장면 865: 긍정\n",
            "장면 866: 긍정\n",
            "장면 867: 긍정\n",
            "장면 868: 긍정\n",
            "장면 869: 긍정\n",
            "장면 870: 부정\n",
            "장면 871: 긍정\n",
            "장면 872: 부정\n",
            "장면 873: 부정\n",
            "장면 874: 부정\n",
            "장면 875: 긍정\n",
            "장면 876: 부정\n",
            "장면 877: 긍정\n",
            "장면 878: 긍정\n",
            "장면 879: 긍정\n",
            "장면 880: 긍정\n",
            "장면 881: 긍정\n",
            "장면 882: 긍정\n",
            "장면 883: 긍정\n",
            "장면 884: 긍정\n",
            "장면 885: 부정\n",
            "장면 886: 부정\n",
            "장면 887: 긍정\n",
            "장면 888: 부정\n",
            "장면 889: 긍정\n",
            "장면 890: 긍정\n",
            "장면 891: 긍정\n",
            "장면 892: 긍정\n",
            "장면 893: 부정\n",
            "장면 894: 긍정\n",
            "장면 895: 부정\n",
            "장면 896: 긍정\n",
            "장면 897: 긍정\n",
            "장면 898: 긍정\n",
            "장면 899: 긍정\n",
            "장면 900: 긍정\n",
            "장면 901: 긍정\n",
            "장면 902: 긍정\n",
            "장면 903: 긍정\n",
            "장면 904: 긍정\n",
            "장면 905: 부정\n",
            "장면 906: 긍정\n",
            "장면 907: 부정\n",
            "장면 908: 부정\n",
            "장면 909: 긍정\n",
            "장면 910: 긍정\n",
            "장면 911: 부정\n",
            "장면 912: 긍정\n",
            "장면 913: 긍정\n",
            "장면 914: 긍정\n",
            "장면 915: 긍정\n",
            "장면 916: 긍정\n",
            "장면 917: 긍정\n",
            "장면 918: 긍정\n",
            "장면 919: 긍정\n",
            "장면 920: 부정\n",
            "장면 921: 부정\n",
            "장면 922: 긍정\n",
            "장면 923: 긍정\n",
            "장면 924: 긍정\n",
            "장면 925: 긍정\n",
            "장면 926: 긍정\n",
            "장면 927: 부정\n",
            "장면 928: 긍정\n",
            "장면 929: 긍정\n",
            "장면 930: 긍정\n",
            "장면 931: 긍정\n",
            "장면 932: 긍정\n",
            "장면 933: 부정\n",
            "장면 934: 긍정\n",
            "장면 935: 부정\n",
            "장면 936: 긍정\n",
            "장면 937: 부정\n",
            "장면 938: 긍정\n",
            "장면 939: 부정\n",
            "장면 940: 긍정\n",
            "장면 941: 부정\n",
            "장면 942: 긍정\n",
            "장면 943: 긍정\n",
            "장면 944: 부정\n",
            "장면 945: 긍정\n",
            "장면 946: 부정\n",
            "장면 947: 부정\n",
            "장면 948: 긍정\n",
            "장면 949: 긍정\n",
            "장면 950: 긍정\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (3) 문제 3 : 위의 텍스트를 요약하여라"
      ],
      "metadata": {
        "id": "idCV86gawsyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "# 문장으로 분할\n",
        "sentences = nltk.sent_tokenize(hamlet)\n",
        "\n",
        "# CountVectorizer를 사용하여 단어 벡터화\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "X = count_vectorizer.fit_transform(sentences)\n",
        "\n",
        "# LDA 모델 훈련\n",
        "lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "lda_model.fit(X)\n",
        "\n",
        "# 각 주제의 중요한 단어 추출\n",
        "feature_names = count_vectorizer.get_feature_names_out()\n",
        "n_top_words = 5\n",
        "summary_topics = []\n",
        "for topic_idx, topic in enumerate(lda_model.components_):\n",
        "    top_words_idx = topic.argsort()[:-n_top_words - 1:-1]\n",
        "    top_words = [feature_names[i] for i in top_words_idx]\n",
        "    summary_topics.append(top_words)\n",
        "\n",
        "# 요약 작성\n",
        "summary = '\\n'.join([f\"주제 {i+1}: {' '.join(topic_words)}\" for i, topic_words in enumerate(summary_topics)])\n",
        "\n",
        "print(\"요약:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HirmKXgcwxAn",
        "outputId": "6855ee97-1aa8-48e4-83fc-c49c8300f107"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "요약:\n",
            "주제 1: thou like thy exeunt oh\n",
            "주제 2: haue lord pol polon qu\n",
            "주제 3: ham lord hamlet haue good\n",
            "주제 4: king enter mar good queene\n",
            "주제 5: hor ophe shall come loue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 조원들과 만든 문제와 답을 공유해보세요."
      ],
      "metadata": {
        "id": "2EvgMg6VsMz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 1 : hamlet[:5000]에서 영어가 아닌 숫자/특수문자를 공란으로 변경하기\n",
        "import re\n",
        "\n",
        "remove_hamlet = re.sub('[^a-xA-Z]', ' ', hamlet[:5000])\n",
        "remove_hamlet\n",
        "\n",
        "# 문제 2 : SentimentIntensityAnalyzer를 이용해 hamlet[:5000] 감성 점수 구하기\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "senti_analyzer = SentimentIntensityAnalyzer()\n",
        "senti_scores = senti_analyzer.polarity_scores(hamlet[:5000])\n",
        "print(senti_scores)"
      ],
      "metadata": {
        "id": "a_l-4BAwsPlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2fbffc7-395c-4b36-f4a0-fe70bf22fe43"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.058, 'neu': 0.866, 'pos': 0.076, 'compound': 0.894}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "### (1) 문제 1 : hamlet이 긍정 감성인지 부정 감성인지 예측하기\n",
        "---\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# 간단한 NTLK PennTreebank Tag를 기반으로 WordNet기반의 품사 Tag로 변환\n",
        "def penn_to_wn(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    elif tag.startswith('V'):\n",
        "        return wn.VERB\n",
        "    return\n",
        "---\n",
        "import nltk\n",
        "nltk.download('sentiwordnet')\n",
        "---\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "\n",
        "def swn_polarity(text):\n",
        "    # 감성 지수 초기화\n",
        "    sentiment = 0.0\n",
        "    tokens_count = 0\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    raw_sentences = sent_tokenize(text)\n",
        "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산\n",
        "    for raw_sentence in raw_sentences:\n",
        "        # NTLK 기반의 품사 태깅 문장 추출\n",
        "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
        "        for word , tag in tagged_sentence:\n",
        "\n",
        "            # WordNet 기반 품사 태깅과 어근 추출\n",
        "            wn_tag = penn_to_wn(tag)\n",
        "            if wn_tag not in (wn.NOUN , wn.ADJ, wn.ADV):\n",
        "                continue\n",
        "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "            if not lemma:\n",
        "                continue\n",
        "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성.\n",
        "            synsets = wn.synsets(lemma , pos=wn_tag)\n",
        "            if not synsets:\n",
        "                continue\n",
        "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
        "            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산.\n",
        "            synset = synsets[0]\n",
        "            swn_synset = swn.senti_synset(synset.name())\n",
        "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())\n",
        "            tokens_count += 1\n",
        "\n",
        "    if not tokens_count:\n",
        "        return 0\n",
        "\n",
        "    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
        "    if sentiment >= 0 :\n",
        "        return 1\n",
        "\n",
        "    return 0\n",
        "---\n",
        "swn_polarity(hamlet)\n",
        "---\n",
        "### (2) 문제 2: hamlet에서 가장 긍정적인 단어, 가장 부정적인 단어, 가장 객관적인 단어\n",
        "---\n",
        "def most_pos_neg_obj_word(text):\n",
        "    positive_words = []\n",
        "    negative_words = []\n",
        "    objective_words = []\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    raw_sentences = sent_tokenize(text)\n",
        "    for raw_sentence in raw_sentences:\n",
        "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
        "        for word , tag in tagged_sentence:\n",
        "            wn_tag = penn_to_wn(tag)\n",
        "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
        "                continue\n",
        "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "            if not lemma:\n",
        "                continue\n",
        "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
        "            if not synsets:\n",
        "                continue\n",
        "            synset = synsets[0]\n",
        "            swn_synset = swn.senti_synset(synset.name())\n",
        "            if swn_synset.pos_score() > swn_synset.neg_score():\n",
        "                positive_words.append((lemma, swn_synset.pos_score()))\n",
        "            elif swn_synset.pos_score() < swn_synset.neg_score():\n",
        "                negative_words.append((lemma, swn_synset.neg_score()))\n",
        "            objective_words.append((lemma, swn_synset.obj_score()))\n",
        "\n",
        "    positive_words.sort(key=lambda x: x[1], reverse=True)\n",
        "    negative_words.sort(key=lambda x: x[1], reverse=True)\n",
        "    objective_words.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return positive_words[0], negative_words[0], objective_words[0]\n",
        "---\n",
        "most_pos_neg_obj_word(hamlet)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "xhv5qsZOxNdM",
        "outputId": "ac3d86e7-6467-409d-d772-1036679544d0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n### (1) 문제 1 : hamlet이 긍정 감성인지 부정 감성인지 예측하기\\n---\\nfrom nltk.corpus import wordnet as wn\\n\\n# 간단한 NTLK PennTreebank Tag를 기반으로 WordNet기반의 품사 Tag로 변환\\ndef penn_to_wn(tag):\\n    if tag.startswith('J'):\\n        return wn.ADJ\\n    elif tag.startswith('N'):\\n        return wn.NOUN\\n    elif tag.startswith('R'):\\n        return wn.ADV\\n    elif tag.startswith('V'):\\n        return wn.VERB\\n    return\\n---\\nimport nltk\\nnltk.download('sentiwordnet')\\n---\\nfrom nltk.stem import WordNetLemmatizer\\nfrom nltk.corpus import sentiwordnet as swn\\nfrom nltk import sent_tokenize, word_tokenize, pos_tag\\n\\ndef swn_polarity(text):\\n    # 감성 지수 초기화\\n    sentiment = 0.0\\n    tokens_count = 0\\n\\n    lemmatizer = WordNetLemmatizer()\\n    raw_sentences = sent_tokenize(text)\\n    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산\\n    for raw_sentence in raw_sentences:\\n        # NTLK 기반의 품사 태깅 문장 추출\\n        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\\n        for word , tag in tagged_sentence:\\n\\n            # WordNet 기반 품사 태깅과 어근 추출\\n            wn_tag = penn_to_wn(tag)\\n            if wn_tag not in (wn.NOUN , wn.ADJ, wn.ADV):\\n                continue\\n            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\\n            if not lemma:\\n                continue\\n            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성.\\n            synsets = wn.synsets(lemma , pos=wn_tag)\\n            if not synsets:\\n                continue\\n            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\\n            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산.\\n            synset = synsets[0]\\n            swn_synset = swn.senti_synset(synset.name())\\n            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())\\n            tokens_count += 1\\n\\n    if not tokens_count:\\n        return 0\\n\\n    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\\n    if sentiment >= 0 :\\n        return 1\\n\\n    return 0\\n---\\nswn_polarity(hamlet)\\n---\\n### (2) 문제 2: hamlet에서 가장 긍정적인 단어, 가장 부정적인 단어, 가장 객관적인 단어\\n---\\ndef most_pos_neg_obj_word(text):\\n    positive_words = []\\n    negative_words = []\\n    objective_words = []\\n\\n    lemmatizer = WordNetLemmatizer()\\n    raw_sentences = sent_tokenize(text)\\n    for raw_sentence in raw_sentences:\\n        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\\n        for word , tag in tagged_sentence:\\n            wn_tag = penn_to_wn(tag)\\n            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\\n                continue\\n            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\\n            if not lemma:\\n                continue\\n            synsets = wn.synsets(lemma, pos=wn_tag)\\n            if not synsets:\\n                continue\\n            synset = synsets[0]\\n            swn_synset = swn.senti_synset(synset.name())\\n            if swn_synset.pos_score() > swn_synset.neg_score():\\n                positive_words.append((lemma, swn_synset.pos_score()))\\n            elif swn_synset.pos_score() < swn_synset.neg_score():\\n                negative_words.append((lemma, swn_synset.neg_score()))\\n            objective_words.append((lemma, swn_synset.obj_score()))\\n\\n    positive_words.sort(key=lambda x: x[1], reverse=True)\\n    negative_words.sort(key=lambda x: x[1], reverse=True)\\n    objective_words.sort(key=lambda x: x[1], reverse=True)\\n\\n    return positive_words[0], negative_words[0], objective_words[0]\\n---\\nmost_pos_neg_obj_word(hamlet)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) 문제 1 : 제목의 감성지수를 구해보아라\n",
        "\n",
        "#import nltk\n",
        "#nltk.download('all')\n",
        "#from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "def get_sentiment(title):\n",
        "    sent = SentimentIntensityAnalyzer()\n",
        "    # 감성분석 수행\n",
        "    sentiment_score = sent.polarity_scores(title)\n",
        "    return sentiment_score['compound']\n",
        "\n",
        "title = \"The Tragedie of Hamlet by William Shakespeare 1599\"\n",
        "sentiment = get_sentiment(title)\n",
        "print(f\"제목: {title}\")\n",
        "print(f\"감성지수: {sentiment}\")\n",
        "\n",
        "\n",
        "# (2) 문제 2: synsets()를 이용하여 hamlet에서 랜덤으로 뽑은 단어에 대해 WordNet에 등재된 모든 Synset 객체 반환해보아라\n",
        "\n",
        "import random\n",
        "def get_random_words(text):\n",
        "    words = text.split()  # 문장을 단어로 나눔\n",
        "    random_word = random.sample(words, 1)  # 단어 중에서 임의로 선택\n",
        "    return random_word\n",
        "\n",
        "text = hamlet\n",
        "random_word = get_random_words(text)\n",
        "print(\"임의로 선택된 단어:\", random_word)\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "term =\"heart\"\n",
        "synsets = wn.synsets(term)\n",
        "print(\"synsets() 반환 type :\", type(synsets))\n",
        "print(\"synsets() 반환 값 개수:\", len(synsets))\n",
        "print(\"synsets() 반환 값:\", synsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPoNDLFfx2b9",
        "outputId": "3ac9450d-5dfe-4a38-e16b-181ab77d3623"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "제목: The Tragedie of Hamlet by William Shakespeare 1599\n",
            "감성지수: 0.0\n",
            "임의로 선택된 단어: ['If']\n",
            "synsets() 반환 type : <class 'list'>\n",
            "synsets() 반환 값 개수: 10\n",
            "synsets() 반환 값: [Synset('heart.n.01'), Synset('heart.n.02'), Synset('heart.n.03'), Synset('center.n.01'), Synset('kernel.n.03'), Synset('heart.n.06'), Synset('heart.n.07'), Synset('heart.n.08'), Synset('affection.n.01'), Synset('heart.n.10')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 1 : WordNet을 사용하여 hamlet이라는 단어의 synsets를 생성하고 확인해보시오\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "term = 'hamlet'\n",
        "\n",
        "# 'present'라는 단어로 wordnet의 synsets 생성.\n",
        "synsets = wn.synsets(term)\n",
        "print('synsets() 반환 type : ', type(synsets))\n",
        "print('synsets() 반환 값 개수 : ', len(synsets))\n",
        "print('synsets() 반환 값 : ', synsets)\n",
        "\n",
        "for synset in synsets :\n",
        "  print('##### Synset name : ', synset.name(), '#####')\n",
        "  print('POS : ', synset.lexname())\n",
        "  print('Definition : ', synset.definition())\n",
        "  print('Lemmas : ', synset.lemma_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4lHcjmcx_wc",
        "outputId": "49a0dcc3-4124-4bbf-b716-bcba4e86c82d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "synsets() 반환 type :  <class 'list'>\n",
            "synsets() 반환 값 개수 :  3\n",
            "synsets() 반환 값 :  [Synset('hamlet.n.01'), Synset('hamlet.n.02'), Synset('village.n.02')]\n",
            "##### Synset name :  hamlet.n.01 #####\n",
            "POS :  noun.group\n",
            "Definition :  a community of people smaller than a village\n",
            "Lemmas :  ['hamlet', 'crossroads']\n",
            "##### Synset name :  hamlet.n.02 #####\n",
            "POS :  noun.person\n",
            "Definition :  the hero of William Shakespeare's tragedy who hoped to avenge the murder of his father\n",
            "Lemmas :  ['Hamlet']\n",
            "##### Synset name :  village.n.02 #####\n",
            "POS :  noun.location\n",
            "Definition :  a settlement smaller than a town\n",
            "Lemmas :  ['village', 'hamlet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 2 : hamlet 10000개까지의 글자를 대상으로 단어 토큰화를 진행하고 스탑워드를 제거하시오\n",
        "\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "\n",
        "hamlet_10000 = hamlet[:10000]\n",
        "\n",
        "# 여러 개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화하게 만드는 함수 생성\n",
        "def tokenize_text(text):\n",
        "\n",
        "    # 문장별로 분리 토큰\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # 분리된 문장별 단어 토큰화\n",
        "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
        "    return word_tokens\n",
        "\n",
        "# 여러 문장에 대해 문장별 단어 토큰화 수행\n",
        "word_tokens = tokenize_text(hamlet_10000)\n",
        "print(type(word_tokens), len(word_tokens))\n",
        "print(word_tokens)\n",
        "\n",
        "\n",
        "import nltk\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "all_tokens = []\n",
        "\n",
        "# 위 예제에서 3개의 문장별로 얻은 word_tokens list에 대해 스톱워드를 제거하는 반복문\n",
        "for sentence in word_tokens :\n",
        "    # 개별 문장별로 토큰화된 문장 list에 대해 스톱 워드를 제거하는 반복문\n",
        "    for word in sentence :\n",
        "        # 소문자로 모두 변환한다.\n",
        "        word = word.lower()\n",
        "\n",
        "        # 토큰화된 개별 단어가 스톱워드의 단어에 포함되지 않으면 word_tokens에 추가\n",
        "        if word not in stopwords :\n",
        "            all_tokens.append(word)\n",
        "\n",
        "print(all_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFSPJ_NWyE8G",
        "outputId": "7fd15cfa-01f5-4239-e786-676664adc6fa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 132\n",
            "[['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', 'William', 'Shakespeare', '1599', ']', 'Actus', 'Primus', '.'], ['Scoena', 'Prima', '.'], ['Enter', 'Barnardo', 'and', 'Francisco', 'two', 'Centinels', '.'], ['Barnardo', '.'], ['Who', \"'s\", 'there', '?'], ['Fran', '.'], ['Nay', 'answer', 'me', ':', 'Stand', '&', 'vnfold', 'your', 'selfe', 'Bar', '.'], ['Long', 'liue', 'the', 'King', 'Fran', '.'], ['Barnardo', '?'], ['Bar', '.'], ['He', 'Fran', '.'], ['You', 'come', 'most', 'carefully', 'vpon', 'your', 'houre', 'Bar', '.'], [\"'T\", 'is', 'now', 'strook', 'twelue', ',', 'get', 'thee', 'to', 'bed', 'Francisco', 'Fran', '.'], ['For', 'this', 'releefe', 'much', 'thankes', ':', \"'T\", 'is', 'bitter', 'cold', ',', 'And', 'I', 'am', 'sicke', 'at', 'heart', 'Barn', '.'], ['Haue', 'you', 'had', 'quiet', 'Guard', '?'], ['Fran', '.'], ['Not', 'a', 'Mouse', 'stirring', 'Barn', '.'], ['Well', ',', 'goodnight', '.'], ['If', 'you', 'do', 'meet', 'Horatio', 'and', 'Marcellus', ',', 'the', 'Riuals', 'of', 'my', 'Watch', ',', 'bid', 'them', 'make', 'hast', '.'], ['Enter', 'Horatio', 'and', 'Marcellus', '.'], ['Fran', '.'], ['I', 'thinke', 'I', 'heare', 'them', '.'], ['Stand', ':', 'who', \"'s\", 'there', '?'], ['Hor', '.'], ['Friends', 'to', 'this', 'ground', 'Mar', '.'], ['And', 'Leige-men', 'to', 'the', 'Dane', 'Fran', '.'], ['Giue', 'you', 'good', 'night', 'Mar', '.'], ['O', 'farwel', 'honest', 'Soldier', ',', 'who', 'hath', 'relieu', \"'d\", 'you', '?'], ['Fra', '.'], ['Barnardo', 'ha', \"'s\", 'my', 'place', ':', 'giue', 'you', 'goodnight', '.'], ['Exit', 'Fran', '.'], ['Mar', '.'], ['Holla', 'Barnardo', 'Bar', '.'], ['Say', ',', 'what', 'is', 'Horatio', 'there', '?'], ['Hor', '.'], ['A', 'peece', 'of', 'him', 'Bar', '.'], ['Welcome', 'Horatio', ',', 'welcome', 'good', 'Marcellus', 'Mar', '.'], ['What', ',', 'ha', \"'s\", 'this', 'thing', 'appear', \"'d\", 'againe', 'to', 'night', 'Bar', '.'], ['I', 'haue', 'seene', 'nothing', 'Mar', '.'], ['Horatio', 'saies', ',', \"'t\", 'is', 'but', 'our', 'Fantasie', ',', 'And', 'will', 'not', 'let', 'beleefe', 'take', 'hold', 'of', 'him', 'Touching', 'this', 'dreaded', 'sight', ',', 'twice', 'seene', 'of', 'vs', ',', 'Therefore', 'I', 'haue', 'intreated', 'him', 'along', 'With', 'vs', ',', 'to', 'watch', 'the', 'minutes', 'of', 'this', 'Night', ',', 'That', 'if', 'againe', 'this', 'Apparition', 'come', ',', 'He', 'may', 'approue', 'our', 'eyes', ',', 'and', 'speake', 'to', 'it', 'Hor', '.'], ['Tush', ',', 'tush', ',', \"'twill\", 'not', 'appeare', 'Bar', '.'], ['Sit', 'downe', 'a-while', ',', 'And', 'let', 'vs', 'once', 'againe', 'assaile', 'your', 'eares', ',', 'That', 'are', 'so', 'fortified', 'against', 'our', 'Story', ',', 'What', 'we', 'two', 'Nights', 'haue', 'seene', 'Hor', '.'], ['Well', ',', 'sit', 'we', 'downe', ',', 'And', 'let', 'vs', 'heare', 'Barnardo', 'speake', 'of', 'this', 'Barn', '.'], ['Last', 'night', 'of', 'all', ',', 'When', 'yond', 'same', 'Starre', 'that', \"'s\", 'Westward', 'from', 'the', 'Pole', 'Had', 'made', 'his', 'course', 't', \"'\", 'illume', 'that', 'part', 'of', 'Heauen', 'Where', 'now', 'it', 'burnes', ',', 'Marcellus', 'and', 'my', 'selfe', ',', 'The', 'Bell', 'then', 'beating', 'one', 'Mar', '.'], ['Peace', ',', 'breake', 'thee', 'of', ':', 'Enter', 'the', 'Ghost', '.'], ['Looke', 'where', 'it', 'comes', 'againe', 'Barn', '.'], ['In', 'the', 'same', 'figure', ',', 'like', 'the', 'King', 'that', \"'s\", 'dead', 'Mar', '.'], ['Thou', 'art', 'a', 'Scholler', ';', 'speake', 'to', 'it', 'Horatio', 'Barn', '.'], ['Lookes', 'it', 'not', 'like', 'the', 'King', '?'], ['Marke', 'it', 'Horatio', 'Hora', '.'], ['Most', 'like', ':', 'It', 'harrowes', 'me', 'with', 'fear', '&', 'wonder', 'Barn', '.'], ['It', 'would', 'be', 'spoke', 'too', 'Mar', '.'], ['Question', 'it', 'Horatio', 'Hor', '.'], ['What', 'art', 'thou', 'that', \"vsurp'st\", 'this', 'time', 'of', 'night', ',', 'Together', 'with', 'that', 'Faire', 'and', 'Warlike', 'forme', 'In', 'which', 'the', 'Maiesty', 'of', 'buried', 'Denmarke', 'Did', 'sometimes', 'march', ':', 'By', 'Heauen', 'I', 'charge', 'thee', 'speake', 'Mar', '.'], ['It', 'is', 'offended', 'Barn', '.'], ['See', ',', 'it', 'stalkes', 'away', 'Hor', '.'], ['Stay', ':', 'speake', ';', 'speake', ':', 'I', 'Charge', 'thee', ',', 'speake', '.'], ['Exit', 'the', 'Ghost', '.'], ['Mar', '.'], [\"'T\", 'is', 'gone', ',', 'and', 'will', 'not', 'answer', 'Barn', '.'], ['How', 'now', 'Horatio', '?'], ['You', 'tremble', '&', 'look', 'pale', ':', 'Is', 'not', 'this', 'something', 'more', 'then', 'Fantasie', '?'], ['What', 'thinke', 'you', 'o', \"n't\", '?'], ['Hor', '.'], ['Before', 'my', 'God', ',', 'I', 'might', 'not', 'this', 'beleeue', 'Without', 'the', 'sensible', 'and', 'true', 'auouch', 'Of', 'mine', 'owne', 'eyes', 'Mar', '.'], ['Is', 'it', 'not', 'like', 'the', 'King', '?'], ['Hor', '.'], ['As', 'thou', 'art', 'to', 'thy', 'selfe', ',', 'Such', 'was', 'the', 'very', 'Armour', 'he', 'had', 'on', ',', 'When', 'th', \"'\", 'Ambitious', 'Norwey', 'combatted', ':', 'So', 'frown', \"'d\", 'he', 'once', ',', 'when', 'in', 'an', 'angry', 'parle', 'He', 'smot', 'the', 'sledded', 'Pollax', 'on', 'the', 'Ice', '.'], [\"'T\", 'is', 'strange', 'Mar', '.'], ['Thus', 'twice', 'before', ',', 'and', 'iust', 'at', 'this', 'dead', 'houre', ',', 'With', 'Martiall', 'stalke', ',', 'hath', 'he', 'gone', 'by', 'our', 'Watch', 'Hor', '.'], ['In', 'what', 'particular', 'thought', 'to', 'work', ',', 'I', 'know', 'not', ':', 'But', 'in', 'the', 'grosse', 'and', 'scope', 'of', 'my', 'Opinion', ',', 'This', 'boades', 'some', 'strange', 'erruption', 'to', 'our', 'State', 'Mar', '.'], ['Good', 'now', 'sit', 'downe', ',', '&', 'tell', 'me', 'he', 'that', 'knowes', 'Why', 'this', 'same', 'strict', 'and', 'most', 'obseruant', 'Watch', ',', 'So', 'nightly', 'toyles', 'the', 'subiect', 'of', 'the', 'Land', ',', 'And', 'why', 'such', 'dayly', 'Cast', 'of', 'Brazon', 'Cannon', 'And', 'Forraigne', 'Mart', 'for', 'Implements', 'of', 'warre', ':', 'Why', 'such', 'impresse', 'of', 'Ship-wrights', ',', 'whose', 'sore', 'Taske', 'Do', \"'s\", 'not', 'diuide', 'the', 'Sunday', 'from', 'the', 'weeke', ',', 'What', 'might', 'be', 'toward', ',', 'that', 'this', 'sweaty', 'hast', 'Doth', 'make', 'the', 'Night', 'ioynt-Labourer', 'with', 'the', 'day', ':', 'Who', \"is't\", 'that', 'can', 'informe', 'me', '?'], ['Hor', '.'], ['That', 'can', 'I', ',', 'At', 'least', 'the', 'whisper', 'goes', 'so', ':', 'Our', 'last', 'King', ',', 'Whose', 'Image', 'euen', 'but', 'now', 'appear', \"'d\", 'to', 'vs', ',', 'Was', '(', 'as', 'you', 'know', ')', 'by', 'Fortinbras', 'of', 'Norway', ',', '(', 'Thereto', 'prick', \"'d\", 'on', 'by', 'a', 'most', 'emulate', 'Pride', ')', 'Dar', \"'d\", 'to', 'the', 'Combate', '.'], ['In', 'which', ',', 'our', 'Valiant', 'Hamlet', ',', '(', 'For', 'so', 'this', 'side', 'of', 'our', 'knowne', 'world', 'esteem', \"'d\", 'him', ')', 'Did', 'slay', 'this', 'Fortinbras', ':', 'who', 'by', 'a', 'Seal', \"'d\", 'Compact', ',', 'Well', 'ratified', 'by', 'Law', ',', 'and', 'Heraldrie', ',', 'Did', 'forfeite', '(', 'with', 'his', 'life', ')', 'all', 'those', 'his', 'Lands', 'Which', 'he', 'stood', 'seiz', \"'d\", 'on', ',', 'to', 'the', 'Conqueror', ':', 'Against', 'the', 'which', ',', 'a', 'Moity', 'competent', 'Was', 'gaged', 'by', 'our', 'King', ':', 'which', 'had', \"return'd\", 'To', 'the', 'Inheritance', 'of', 'Fortinbras', ',', 'Had', 'he', 'bin', 'Vanquisher', ',', 'as', 'by', 'the', 'same', \"Cou'nant\", 'And', 'carriage', 'of', 'the', 'Article', 'designe', ',', 'His', 'fell', 'to', 'Hamlet', '.'], ['Now', 'sir', ',', 'young', 'Fortinbras', ',', 'Of', 'vnimproued', 'Mettle', ',', 'hot', 'and', 'full', ',', 'Hath', 'in', 'the', 'skirts', 'of', 'Norway', ',', 'heere', 'and', 'there', ',', 'Shark', \"'d\", 'vp', 'a', 'List', 'of', 'Landlesse', 'Resolutes', ',', 'For', 'Foode', 'and', 'Diet', ',', 'to', 'some', 'Enterprize', 'That', 'hath', 'a', 'stomacke', 'i', \"n't\", ':', 'which', 'is', 'no', 'other', '(', 'And', 'it', 'doth', 'well', 'appeare', 'vnto', 'our', 'State', ')', 'But', 'to', 'recouer', 'of', 'vs', 'by', 'strong', 'hand', 'And', 'termes', 'Compulsatiue', ',', 'those', 'foresaid', 'Lands', 'So', 'by', 'his', 'Father', 'lost', ':', 'and', 'this', '(', 'I', 'take', 'it', ')', 'Is', 'the', 'maine', 'Motiue', 'of', 'our', 'Preparations', ',', 'The', 'Sourse', 'of', 'this', 'our', 'Watch', ',', 'and', 'the', 'cheefe', 'head', 'Of', 'this', 'post-hast', ',', 'and', 'Romage', 'in', 'the', 'Land', '.'], ['Enter', 'Ghost', 'againe', '.'], ['But', 'soft', ',', 'behold', ':', 'Loe', ',', 'where', 'it', 'comes', 'againe', ':', 'Ile', 'crosse', 'it', ',', 'though', 'it', 'blast', 'me', '.'], ['Stay', 'Illusion', ':', 'If', 'thou', 'hast', 'any', 'sound', ',', 'or', 'vse', 'of', 'Voyce', ',', 'Speake', 'to', 'me', '.'], ['If', 'there', 'be', 'any', 'good', 'thing', 'to', 'be', 'done', ',', 'That', 'may', 'to', 'thee', 'do', 'ease', ',', 'and', 'grace', 'to', 'me', ';', 'speak', 'to', 'me', '.'], ['If', 'thou', 'art', 'priuy', 'to', 'thy', 'Countries', 'Fate', '(', 'Which', 'happily', 'foreknowing', 'may', 'auoyd', ')', 'Oh', 'speake', '.'], ['Or', ',', 'if', 'thou', 'hast', 'vp-hoorded', 'in', 'thy', 'life', 'Extorted', 'Treasure', 'in', 'the', 'wombe', 'of', 'Earth', ',', '(', 'For', 'which', ',', 'they', 'say', ',', 'you', 'Spirits', 'oft', 'walke', 'in', 'death', ')', 'Speake', 'of', 'it', '.'], ['Stay', ',', 'and', 'speake', '.'], ['Stop', 'it', 'Marcellus', 'Mar', '.'], ['Shall', 'I', 'strike', 'at', 'it', 'with', 'my', 'Partizan', '?'], ['Hor', '.'], ['Do', ',', 'if', 'it', 'will', 'not', 'stand', 'Barn', '.'], [\"'T\", 'is', 'heere', 'Hor', '.'], [\"'T\", 'is', 'heere', 'Mar', '.'], [\"'T\", 'is', 'gone', '.'], ['Exit', 'Ghost', '.'], ['We', 'do', 'it', 'wrong', ',', 'being', 'so', 'Maiesticall', 'To', 'offer', 'it', 'the', 'shew', 'of', 'Violence', ',', 'For', 'it', 'is', 'as', 'the', 'Ayre', ',', 'invulnerable', ',', 'And', 'our', 'vaine', 'blowes', ',', 'malicious', 'Mockery', 'Barn', '.'], ['It', 'was', 'about', 'to', 'speake', ',', 'when', 'the', 'Cocke', 'crew', 'Hor', '.'], ['And', 'then', 'it', 'started', ',', 'like', 'a', 'guilty', 'thing', 'Vpon', 'a', 'fearfull', 'Summons', '.'], ['I', 'haue', 'heard', ',', 'The', 'Cocke', 'that', 'is', 'the', 'Trumpet', 'to', 'the', 'day', ',', 'Doth', 'with', 'his', 'lofty', 'and', 'shrill-sounding', 'Throate', 'Awake', 'the', 'God', 'of', 'Day', ':', 'and', 'at', 'his', 'warning', ',', 'Whether', 'in', 'Sea', ',', 'or', 'Fire', ',', 'in', 'Earth', ',', 'or', 'Ayre', ',', 'Th', \"'\", 'extrauagant', ',', 'and', 'erring', 'Spirit', ',', 'hyes', 'To', 'his', 'Confine', '.'], ['And', 'of', 'the', 'truth', 'heerein', ',', 'This', 'present', 'Obiect', 'made', 'probation', 'Mar', '.'], ['It', 'faded', 'on', 'the', 'crowing', 'of', 'the', 'Cocke', '.'], ['Some', 'sayes', ',', 'that', 'euer', \"'gainst\", 'that', 'Season', 'comes', 'Wherein', 'our', 'Sauiours', 'Birch', 'is', 'celebrated', ',', 'The', 'Bird', 'of', 'Dawning', 'singeth', 'all', 'night', 'long', ':', 'And', 'then', '(', 'they', 'say', ')', 'no', 'Spirit', 'can', 'walke', 'abroad', ',', 'The', 'nights', 'are', 'wholsome', ',', 'then', 'no', 'Planets', 'strike', ',', 'No', 'Faiery', 'talkes', ',', 'nor', 'Witch', 'hath', 'power', 'to', 'Charme', ':', 'So', 'hallow', \"'d\", ',', 'and', 'so', 'gracious', 'is', 'the', 'time', 'Hor', '.'], ['So', 'haue', 'I', 'heard', ',', 'and', 'do', 'in', 'part', 'beleeue', 'it', '.'], ['But', 'looke', ',', 'the', 'Morne', 'in', 'Russet', 'mantle', 'clad', ',', 'Walkes', 'o', \"'re\", 'the', 'dew', 'of', 'yon', 'high', 'Easterne', 'Hill', ',', 'Breake', 'we', 'our', 'Watch', 'vp', ',', 'and', 'by', 'my', 'aduice', 'Let', 'vs', 'impart', 'what', 'we', 'haue', 'seene', 'to', 'night', 'Vnto', 'yong', 'Hamlet', '.'], ['For', 'vpon', 'my', 'life', ',', 'This', 'Spirit', 'dumbe', 'to', 'vs', ',', 'will', 'speake', 'to', 'him', ':', 'Do', 'you', 'consent', 'we', 'shall', 'acquaint', 'him', 'with', 'it', ',', 'As', 'needfull', 'in', 'our', 'Loues', ',', 'fitting', 'our', 'Duty', '?'], ['Mar', '.'], ['Let', \"do't\", 'I', 'pray', ',', 'and', 'I', 'this', 'morning', 'know', 'Where', 'we', 'shall', 'finde', 'him', 'most', 'conueniently', '.'], ['Exeunt', '.'], ['Scena', 'Secunda', '.'], ['Enter', 'Claudius', 'King', 'of', 'Denmarke', ',', 'Gertrude', 'the', 'Queene', ',', 'Hamlet', ',', 'Polonius', ',', 'Laertes', ',', 'and', 'his', 'Sister', 'Ophelia', ',', 'Lords', 'Attendant', '.'], ['King', '.'], ['Though', 'yet', 'of', 'Hamlet', 'our', 'deere', 'Brothers', 'death', 'The', 'memory', 'be', 'greene', ':', 'and', 'that', 'it', 'vs', 'befitted', 'To', 'beare', 'our', 'hearts', 'in', 'greefe', ',', 'and', 'our', 'whole', 'Kingdome', 'To', 'be', 'contracted', 'in', 'one', 'brow', 'of', 'woe', ':', 'Yet', 'so', 'farre', 'hath', 'Discretion', 'fought', 'with', 'Nature', ',', 'That', 'we', 'with', 'wisest', 'sorrow', 'thinke', 'on', 'him', ',', 'Together', 'with', 'remembrance', 'of', 'our', 'selues', '.'], ['Therefore', 'our', 'sometimes', 'Sister', ',', 'now', 'our', 'Queene', ',', 'Th', \"'\", 'imperiall', 'Ioyntresse', 'of', 'this', 'warlike', 'State', ',', 'Haue', 'we', ',', 'as', \"'twere\", ',', 'with', 'a', 'defeated', 'ioy', ',', 'With', 'one', 'Auspicious', ',', 'and', 'one', 'Dropping', 'eye', ',', 'With', 'mirth', 'in', 'Funerall', ',', 'and', 'with', 'Dirge', 'in', 'Marriage', ',', 'In', 'equall', 'Scale', 'weighing', 'Delight', 'and', 'Dole', 'Taken', 'to', 'Wife', ';', 'nor', 'haue', 'we', 'heerein', \"barr'd\", 'Your', 'better', 'Wisedomes', ',', 'which', 'haue', 'freely', 'gone', 'With', 'this', 'affaire', 'along', ',', 'for', 'all', 'our', 'Thankes', '.'], ['Now', 'followes', ',', 'that', 'you', 'know', 'young', 'Fortinbras', ',', 'Holding', 'a', 'weake', 'supposall', 'of', 'our', 'worth', ';', 'Or', 'thinking', 'by', 'our', 'late', 'deere', 'Brothers', 'death', ',', 'Our', 'State', 'to', 'be', 'disioynt', ',', 'and', 'out', 'of', 'Frame', ',', 'Colleagued', 'with', 'the', 'dreame', 'of', 'his', 'Aduantage', ';', 'He', 'hath', 'not', 'fayl', \"'d\", 'to', 'pester', 'vs', 'with', 'Message', ',', 'Importing', 'the', 'surrender', 'of', 'those', 'Lands', 'Lost', 'by', 'his', 'Father', ':', 'with', 'all', 'Bonds', 'of', 'Law', 'To', 'our', 'most', 'valiant', 'Brother', '.'], ['So', 'much', 'for', 'him', '.'], ['Enter', 'Voltemand', 'and', 'Cornelius', '.'], ['Now', 'for', 'our', 'selfe', ',', 'and', 'for', 'this', 'time', 'of', 'meeting', 'Thus', 'much', 'the', 'businesse', 'is', '.'], ['We', 'haue', 'heere', 'writ', 'To', 'Norway', ',', 'Vncle', 'of', 'young', 'Fortinbras', ',', 'Who', 'Impotent', 'and', 'Bedrid', ',', 'scarsely', 'heares', 'Of', 'this', 'his', 'Nephewes', 'purpose', ',', 'to', 'suppresse', 'His', 'further', 'gate', 'heerein', '.'], ['In', 'that', 'the', 'Leuies', ',', 'The', 'Lists', ',', 'and', 'full', 'proportions', 'are', 'all', 'made', 'Out', 'of', 'his', 'subiect', ':', 'and', 'we', 'heere', 'dispatch', 'You', 'good', 'Cornelius', ',', 'and', 'you', 'Voltemand', ',', 'For', 'bearing', 'of', 'this', 'greeting', 'to', 'old', 'Norway', ',', 'Giuing', 'to', 'you', 'no', 'further', 'personall', 'power', 'To', 'businesse', 'with', 'the', 'King', ',', 'more', 'then', 'the', 'scope', 'Of', 'these', 'dilated', 'Articles', 'allow', ':', 'Farewell', ',', 'and', 'let', 'your', 'hast', 'commend', 'your', 'duty', 'Volt', '.'], ['In', 'that', ',', 'and', 'all', 'things', ',', 'will', 'we', 'shew', 'our', 'duty', 'King', '.'], ['We', 'doubt', 'it', 'nothing', ',', 'heartily', 'farewell', '.'], ['Exit', 'Voltemand', 'and', 'Cornelius', '.'], ['And', 'now', 'Laertes', ',', 'what', \"'s\", 'the', 'newes', 'with', 'you', '?'], ['You', 'told', 'vs', 'of', 'some', 'suite', '.'], ['What', \"is't\", 'Laertes', '?'], ['You', 'can', 'not', 'speake', 'of', 'Reason', 'to', 'the', 'Dane', ',', 'And', 'loose', 'your', 'voyce', '.'], ['What', \"would'st\", 'thou', 'beg', 'Laertes', ',', 'That', 'shall', 'not', 'be', 'my', 'Offer', ',', 'not', 'thy', 'Asking', '?'], ['The', 'Head', 'is', 'not', 'more', 'Natiue', 'to', 'the', 'Heart', ',', 'The', 'Hand', 'more', 'instrumentall', 'to', 'the', 'Mouth', ',', 'Then', 'is', 'the', 'Throne', 'of', 'Denmarke', 'to', 'thy', 'Father', '.'], ['What', \"would'st\", 'thou', 'haue', 'Laertes', '?'], ['Laer', '.'], ['Dread', 'my', 'Lord', ',', 'Your', 'leaue', 'and', 'fauour', 'to', 'returne', 'to', 'France', ',', 'From', 'whence', ',', 'though', 'willingly', 'I', 'came', 'to', 'Denmarke', 'To', 'shew', 'my', 'duty', 'in', 'your', 'Coronation', ',', 'Yet', 'now', 'I', 'must', 'confesse', ',', 'that', 'duty', 'done', ',', 'My', 'thoughts', 'and', 'wishes', 'bend', 'againe', 'towards', 'France', ',', 'And', 'bow', 'them', 'to', 'your', 'gracious', 'leaue', 'and', 'pardon', 'King', '.'], ['Haue', 'you', 'your', 'Fathers', 'leaue', '?'], ['What', 'sayes', 'Pollonius', '?'], ['Pol', '.'], ['He', 'hath', 'my', 'Lord', ':', 'I', 'do', 'beseech', 'you', 'giue', 'him', 'leaue', 'to', 'go', 'King', '.'], ['Take', 'thy']]\n",
            "['[', 'tragedie', 'hamlet', 'william', 'shakespeare', '1599', ']', 'actus', 'primus', '.', 'scoena', 'prima', '.', 'enter', 'barnardo', 'francisco', 'two', 'centinels', '.', 'barnardo', '.', \"'s\", '?', 'fran', '.', 'nay', 'answer', ':', 'stand', '&', 'vnfold', 'selfe', 'bar', '.', 'long', 'liue', 'king', 'fran', '.', 'barnardo', '?', 'bar', '.', 'fran', '.', 'come', 'carefully', 'vpon', 'houre', 'bar', '.', \"'t\", 'strook', 'twelue', ',', 'get', 'thee', 'bed', 'francisco', 'fran', '.', 'releefe', 'much', 'thankes', ':', \"'t\", 'bitter', 'cold', ',', 'sicke', 'heart', 'barn', '.', 'haue', 'quiet', 'guard', '?', 'fran', '.', 'mouse', 'stirring', 'barn', '.', 'well', ',', 'goodnight', '.', 'meet', 'horatio', 'marcellus', ',', 'riuals', 'watch', ',', 'bid', 'make', 'hast', '.', 'enter', 'horatio', 'marcellus', '.', 'fran', '.', 'thinke', 'heare', '.', 'stand', ':', \"'s\", '?', 'hor', '.', 'friends', 'ground', 'mar', '.', 'leige-men', 'dane', 'fran', '.', 'giue', 'good', 'night', 'mar', '.', 'farwel', 'honest', 'soldier', ',', 'hath', 'relieu', \"'d\", '?', 'fra', '.', 'barnardo', 'ha', \"'s\", 'place', ':', 'giue', 'goodnight', '.', 'exit', 'fran', '.', 'mar', '.', 'holla', 'barnardo', 'bar', '.', 'say', ',', 'horatio', '?', 'hor', '.', 'peece', 'bar', '.', 'welcome', 'horatio', ',', 'welcome', 'good', 'marcellus', 'mar', '.', ',', 'ha', \"'s\", 'thing', 'appear', \"'d\", 'againe', 'night', 'bar', '.', 'haue', 'seene', 'nothing', 'mar', '.', 'horatio', 'saies', ',', \"'t\", 'fantasie', ',', 'let', 'beleefe', 'take', 'hold', 'touching', 'dreaded', 'sight', ',', 'twice', 'seene', 'vs', ',', 'therefore', 'haue', 'intreated', 'along', 'vs', ',', 'watch', 'minutes', 'night', ',', 'againe', 'apparition', 'come', ',', 'may', 'approue', 'eyes', ',', 'speake', 'hor', '.', 'tush', ',', 'tush', ',', \"'twill\", 'appeare', 'bar', '.', 'sit', 'downe', 'a-while', ',', 'let', 'vs', 'againe', 'assaile', 'eares', ',', 'fortified', 'story', ',', 'two', 'nights', 'haue', 'seene', 'hor', '.', 'well', ',', 'sit', 'downe', ',', 'let', 'vs', 'heare', 'barnardo', 'speake', 'barn', '.', 'last', 'night', ',', 'yond', 'starre', \"'s\", 'westward', 'pole', 'made', 'course', \"'\", 'illume', 'part', 'heauen', 'burnes', ',', 'marcellus', 'selfe', ',', 'bell', 'beating', 'one', 'mar', '.', 'peace', ',', 'breake', 'thee', ':', 'enter', 'ghost', '.', 'looke', 'comes', 'againe', 'barn', '.', 'figure', ',', 'like', 'king', \"'s\", 'dead', 'mar', '.', 'thou', 'art', 'scholler', ';', 'speake', 'horatio', 'barn', '.', 'lookes', 'like', 'king', '?', 'marke', 'horatio', 'hora', '.', 'like', ':', 'harrowes', 'fear', '&', 'wonder', 'barn', '.', 'would', 'spoke', 'mar', '.', 'question', 'horatio', 'hor', '.', 'art', 'thou', \"vsurp'st\", 'time', 'night', ',', 'together', 'faire', 'warlike', 'forme', 'maiesty', 'buried', 'denmarke', 'sometimes', 'march', ':', 'heauen', 'charge', 'thee', 'speake', 'mar', '.', 'offended', 'barn', '.', 'see', ',', 'stalkes', 'away', 'hor', '.', 'stay', ':', 'speake', ';', 'speake', ':', 'charge', 'thee', ',', 'speake', '.', 'exit', 'ghost', '.', 'mar', '.', \"'t\", 'gone', ',', 'answer', 'barn', '.', 'horatio', '?', 'tremble', '&', 'look', 'pale', ':', 'something', 'fantasie', '?', 'thinke', \"n't\", '?', 'hor', '.', 'god', ',', 'might', 'beleeue', 'without', 'sensible', 'true', 'auouch', 'mine', 'owne', 'eyes', 'mar', '.', 'like', 'king', '?', 'hor', '.', 'thou', 'art', 'thy', 'selfe', ',', 'armour', ',', 'th', \"'\", 'ambitious', 'norwey', 'combatted', ':', 'frown', \"'d\", ',', 'angry', 'parle', 'smot', 'sledded', 'pollax', 'ice', '.', \"'t\", 'strange', 'mar', '.', 'thus', 'twice', ',', 'iust', 'dead', 'houre', ',', 'martiall', 'stalke', ',', 'hath', 'gone', 'watch', 'hor', '.', 'particular', 'thought', 'work', ',', 'know', ':', 'grosse', 'scope', 'opinion', ',', 'boades', 'strange', 'erruption', 'state', 'mar', '.', 'good', 'sit', 'downe', ',', '&', 'tell', 'knowes', 'strict', 'obseruant', 'watch', ',', 'nightly', 'toyles', 'subiect', 'land', ',', 'dayly', 'cast', 'brazon', 'cannon', 'forraigne', 'mart', 'implements', 'warre', ':', 'impresse', 'ship-wrights', ',', 'whose', 'sore', 'taske', \"'s\", 'diuide', 'sunday', 'weeke', ',', 'might', 'toward', ',', 'sweaty', 'hast', 'doth', 'make', 'night', 'ioynt-labourer', 'day', ':', \"is't\", 'informe', '?', 'hor', '.', ',', 'least', 'whisper', 'goes', ':', 'last', 'king', ',', 'whose', 'image', 'euen', 'appear', \"'d\", 'vs', ',', '(', 'know', ')', 'fortinbras', 'norway', ',', '(', 'thereto', 'prick', \"'d\", 'emulate', 'pride', ')', 'dar', \"'d\", 'combate', '.', ',', 'valiant', 'hamlet', ',', '(', 'side', 'knowne', 'world', 'esteem', \"'d\", ')', 'slay', 'fortinbras', ':', 'seal', \"'d\", 'compact', ',', 'well', 'ratified', 'law', ',', 'heraldrie', ',', 'forfeite', '(', 'life', ')', 'lands', 'stood', 'seiz', \"'d\", ',', 'conqueror', ':', ',', 'moity', 'competent', 'gaged', 'king', ':', \"return'd\", 'inheritance', 'fortinbras', ',', 'bin', 'vanquisher', ',', \"cou'nant\", 'carriage', 'article', 'designe', ',', 'fell', 'hamlet', '.', 'sir', ',', 'young', 'fortinbras', ',', 'vnimproued', 'mettle', ',', 'hot', 'full', ',', 'hath', 'skirts', 'norway', ',', 'heere', ',', 'shark', \"'d\", 'vp', 'list', 'landlesse', 'resolutes', ',', 'foode', 'diet', ',', 'enterprize', 'hath', 'stomacke', \"n't\", ':', '(', 'doth', 'well', 'appeare', 'vnto', 'state', ')', 'recouer', 'vs', 'strong', 'hand', 'termes', 'compulsatiue', ',', 'foresaid', 'lands', 'father', 'lost', ':', '(', 'take', ')', 'maine', 'motiue', 'preparations', ',', 'sourse', 'watch', ',', 'cheefe', 'head', 'post-hast', ',', 'romage', 'land', '.', 'enter', 'ghost', 'againe', '.', 'soft', ',', 'behold', ':', 'loe', ',', 'comes', 'againe', ':', 'ile', 'crosse', ',', 'though', 'blast', '.', 'stay', 'illusion', ':', 'thou', 'hast', 'sound', ',', 'vse', 'voyce', ',', 'speake', '.', 'good', 'thing', 'done', ',', 'may', 'thee', 'ease', ',', 'grace', ';', 'speak', '.', 'thou', 'art', 'priuy', 'thy', 'countries', 'fate', '(', 'happily', 'foreknowing', 'may', 'auoyd', ')', 'oh', 'speake', '.', ',', 'thou', 'hast', 'vp-hoorded', 'thy', 'life', 'extorted', 'treasure', 'wombe', 'earth', ',', '(', ',', 'say', ',', 'spirits', 'oft', 'walke', 'death', ')', 'speake', '.', 'stay', ',', 'speake', '.', 'stop', 'marcellus', 'mar', '.', 'shall', 'strike', 'partizan', '?', 'hor', '.', ',', 'stand', 'barn', '.', \"'t\", 'heere', 'hor', '.', \"'t\", 'heere', 'mar', '.', \"'t\", 'gone', '.', 'exit', 'ghost', '.', 'wrong', ',', 'maiesticall', 'offer', 'shew', 'violence', ',', 'ayre', ',', 'invulnerable', ',', 'vaine', 'blowes', ',', 'malicious', 'mockery', 'barn', '.', 'speake', ',', 'cocke', 'crew', 'hor', '.', 'started', ',', 'like', 'guilty', 'thing', 'vpon', 'fearfull', 'summons', '.', 'haue', 'heard', ',', 'cocke', 'trumpet', 'day', ',', 'doth', 'lofty', 'shrill-sounding', 'throate', 'awake', 'god', 'day', ':', 'warning', ',', 'whether', 'sea', ',', 'fire', ',', 'earth', ',', 'ayre', ',', 'th', \"'\", 'extrauagant', ',', 'erring', 'spirit', ',', 'hyes', 'confine', '.', 'truth', 'heerein', ',', 'present', 'obiect', 'made', 'probation', 'mar', '.', 'faded', 'crowing', 'cocke', '.', 'sayes', ',', 'euer', \"'gainst\", 'season', 'comes', 'wherein', 'sauiours', 'birch', 'celebrated', ',', 'bird', 'dawning', 'singeth', 'night', 'long', ':', '(', 'say', ')', 'spirit', 'walke', 'abroad', ',', 'nights', 'wholsome', ',', 'planets', 'strike', ',', 'faiery', 'talkes', ',', 'witch', 'hath', 'power', 'charme', ':', 'hallow', \"'d\", ',', 'gracious', 'time', 'hor', '.', 'haue', 'heard', ',', 'part', 'beleeue', '.', 'looke', ',', 'morne', 'russet', 'mantle', 'clad', ',', 'walkes', \"'re\", 'dew', 'yon', 'high', 'easterne', 'hill', ',', 'breake', 'watch', 'vp', ',', 'aduice', 'let', 'vs', 'impart', 'haue', 'seene', 'night', 'vnto', 'yong', 'hamlet', '.', 'vpon', 'life', ',', 'spirit', 'dumbe', 'vs', ',', 'speake', ':', 'consent', 'shall', 'acquaint', ',', 'needfull', 'loues', ',', 'fitting', 'duty', '?', 'mar', '.', 'let', \"do't\", 'pray', ',', 'morning', 'know', 'shall', 'finde', 'conueniently', '.', 'exeunt', '.', 'scena', 'secunda', '.', 'enter', 'claudius', 'king', 'denmarke', ',', 'gertrude', 'queene', ',', 'hamlet', ',', 'polonius', ',', 'laertes', ',', 'sister', 'ophelia', ',', 'lords', 'attendant', '.', 'king', '.', 'though', 'yet', 'hamlet', 'deere', 'brothers', 'death', 'memory', 'greene', ':', 'vs', 'befitted', 'beare', 'hearts', 'greefe', ',', 'whole', 'kingdome', 'contracted', 'one', 'brow', 'woe', ':', 'yet', 'farre', 'hath', 'discretion', 'fought', 'nature', ',', 'wisest', 'sorrow', 'thinke', ',', 'together', 'remembrance', 'selues', '.', 'therefore', 'sometimes', 'sister', ',', 'queene', ',', 'th', \"'\", 'imperiall', 'ioyntresse', 'warlike', 'state', ',', 'haue', ',', \"'twere\", ',', 'defeated', 'ioy', ',', 'one', 'auspicious', ',', 'one', 'dropping', 'eye', ',', 'mirth', 'funerall', ',', 'dirge', 'marriage', ',', 'equall', 'scale', 'weighing', 'delight', 'dole', 'taken', 'wife', ';', 'haue', 'heerein', \"barr'd\", 'better', 'wisedomes', ',', 'haue', 'freely', 'gone', 'affaire', 'along', ',', 'thankes', '.', 'followes', ',', 'know', 'young', 'fortinbras', ',', 'holding', 'weake', 'supposall', 'worth', ';', 'thinking', 'late', 'deere', 'brothers', 'death', ',', 'state', 'disioynt', ',', 'frame', ',', 'colleagued', 'dreame', 'aduantage', ';', 'hath', 'fayl', \"'d\", 'pester', 'vs', 'message', ',', 'importing', 'surrender', 'lands', 'lost', 'father', ':', 'bonds', 'law', 'valiant', 'brother', '.', 'much', '.', 'enter', 'voltemand', 'cornelius', '.', 'selfe', ',', 'time', 'meeting', 'thus', 'much', 'businesse', '.', 'haue', 'heere', 'writ', 'norway', ',', 'vncle', 'young', 'fortinbras', ',', 'impotent', 'bedrid', ',', 'scarsely', 'heares', 'nephewes', 'purpose', ',', 'suppresse', 'gate', 'heerein', '.', 'leuies', ',', 'lists', ',', 'full', 'proportions', 'made', 'subiect', ':', 'heere', 'dispatch', 'good', 'cornelius', ',', 'voltemand', ',', 'bearing', 'greeting', 'old', 'norway', ',', 'giuing', 'personall', 'power', 'businesse', 'king', ',', 'scope', 'dilated', 'articles', 'allow', ':', 'farewell', ',', 'let', 'hast', 'commend', 'duty', 'volt', '.', ',', 'things', ',', 'shew', 'duty', 'king', '.', 'doubt', 'nothing', ',', 'heartily', 'farewell', '.', 'exit', 'voltemand', 'cornelius', '.', 'laertes', ',', \"'s\", 'newes', '?', 'told', 'vs', 'suite', '.', \"is't\", 'laertes', '?', 'speake', 'reason', 'dane', ',', 'loose', 'voyce', '.', \"would'st\", 'thou', 'beg', 'laertes', ',', 'shall', 'offer', ',', 'thy', 'asking', '?', 'head', 'natiue', 'heart', ',', 'hand', 'instrumentall', 'mouth', ',', 'throne', 'denmarke', 'thy', 'father', '.', \"would'st\", 'thou', 'haue', 'laertes', '?', 'laer', '.', 'dread', 'lord', ',', 'leaue', 'fauour', 'returne', 'france', ',', 'whence', ',', 'though', 'willingly', 'came', 'denmarke', 'shew', 'duty', 'coronation', ',', 'yet', 'must', 'confesse', ',', 'duty', 'done', ',', 'thoughts', 'wishes', 'bend', 'againe', 'towards', 'france', ',', 'bow', 'gracious', 'leaue', 'pardon', 'king', '.', 'haue', 'fathers', 'leaue', '?', 'sayes', 'pollonius', '?', 'pol', '.', 'hath', 'lord', ':', 'beseech', 'giue', 'leaue', 'go', 'king', '.', 'take', 'thy']\n"
          ]
        }
      ]
    }
  ]
}