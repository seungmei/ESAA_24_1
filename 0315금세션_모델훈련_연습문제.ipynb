{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungmei/ESAA_24_1/blob/main/0315%EA%B8%88%EC%84%B8%EC%85%98_%EB%AA%A8%EB%8D%B8%ED%9B%88%EB%A0%A8_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **| 모델 훈련 연습 문제**\n",
        "___\n",
        "- 출처 : 핸즈온 머신러닝 Ch04 연습문제 1, 5, 9, 10\n",
        "- 개념 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
      ],
      "metadata": {
        "id": "zCu72vDHGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?**\n",
        "___\n"
      ],
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "확률적 경사하강법 (SGD) 나 미니배치 경사하강법"
      ],
      "metadata": {
        "id": "5n2vnUs_ecb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?**\n",
        "___"
      ],
      "metadata": {
        "id": "-pDjW5XcHPOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습률이 크면 검증 오차가 일정하게 상승된다. 그리드 탐색을 실시하면 적절한 학습률을 찾을 수 있다."
      ],
      "metadata": {
        "id": "VVHV0dLqeoOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 릿지 회귀를 사용했을 때 훈련 오차가 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 $\\alpha$를 증가시켜야 할까요 아니면 줄여야 할까요?**\n",
        "___"
      ],
      "metadata": {
        "id": "nM7JbsLoy7b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 오차/검증 오차가 비슷하고 높다면 과소적합 됐다고 볼 수 있다.\n",
        "과소적합은 높은 편향에서 비롯된 문제이다.\n",
        "규제 하이퍼 파라미터를 감소시켜서 자유도를 늘려 분산을 키워야 한다."
      ],
      "metadata": {
        "id": "1DNIlZjcfSXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 다음과 같이 사용해야 하는 이유는?**\n",
        "___\n",
        "- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        "- 라쏘 회귀 대신 엘라스틱넷"
      ],
      "metadata": {
        "id": "C8tARu-ZzOGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 평범한 선형 회귀 대신 릿지 회귀\n",
        ": 규제가 있는 모델이 일반적으로 규제가 없는 모델보다 성능이 좋음. 평범한 선형 회귀보다 릿지 회귀가 선호.\n",
        "\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        ": 라쏘 회귀는 l1 패널티를 사용해서 가중치를 완전히 0으로 만드는 경향이 있다. 이는 가장 중요한 가중치를 제외하곤 모두 0이 되는 희소한 모델을 만든다.\n",
        "라쏘 회귀는 자동으로 특성 선택의 효과를 가지므로 단지 몇개의 특성만 실제 유용할 것이라고 의심될 때 사용하면 좋다. 확신이 없다면 릿지 회귀를 사용해야 한다.\n",
        "\n",
        "- 라쏘 회귀 대신 엘라스틱넷\n",
        ": 라쏘가 어떤 경우(몇 개의 특성이 강한 상관관계가 있거나 훈련 샘플보다 특성이 더 많을 때)에는 불규칙하게 행동하므로 엘라스틱넷이 라쏘보다 일반적으로 선호된다. 그러나 추가적인 하이퍼 파라미터가 생긴다.\n",
        "라쏘를 원한다면 차라리 엘라스틱넷에 l1_ratio를 1에 가깝게 설정해서 사용하는 편이 좋다."
      ],
      "metadata": {
        "id": "FmQRiOcIgT6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S8kKR2zMgToi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **추가) 조기 종료를 사용한 배치 경사 하강법으로 iris 데이터를 활용해 소프트맥스 회귀를 구현해보세요(사이킷런은 사용하지 마세요)**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QIZpOEYJVIAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 붓꽃 데이터\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "8pXDQ_fU8Nz0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris['data'][:, (2,3)] #꽃잎 길이, 꽃잎 너비\n",
        "y = iris['target']"
      ],
      "metadata": {
        "id": "gl3zMtS2hAdi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OxSlWvrviHkg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Bias\n",
        "X_with_bias = np.c_[np.ones([len(X),1]),X]\n",
        "# len(X) 개수 만큼 1로 채워진 [ ], [ ]......[ ] array\n",
        "# 2열 -> 3열로 늘어남\n",
        "X_with_bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ephs9jsWi2nF",
        "outputId": "7159185a-4f38-4ed5-92fa-d867e9f324b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1. , 1.4, 0.2],\n",
              "       [1. , 1.4, 0.2],\n",
              "       [1. , 1.3, 0.2],\n",
              "       [1. , 1.5, 0.2],\n",
              "       [1. , 1.4, 0.2],\n",
              "       [1. , 1.7, 0.4],\n",
              "       [1. , 1.4, 0.3],\n",
              "       [1. , 1.5, 0.2],\n",
              "       [1. , 1.4, 0.2],\n",
              "       [1. , 1.5, 0.1],\n",
              "       [1. , 1.5, 0.2],\n",
              "       [1. , 1.6, 0.2],\n",
              "       [1. , 1.4, 0.1],\n",
              "       [1. , 1.1, 0.1],\n",
              "       [1. , 1.2, 0.2],\n",
              "       [1. , 1.5, 0.4],\n",
              "       [1. , 1.3, 0.4],\n",
              "       [1. , 1.4, 0.3],\n",
              "       [1. , 1.7, 0.3],\n",
              "       [1. , 1.5, 0.3],\n",
              "       [1. , 1.7, 0.2],\n",
              "       [1. , 1.5, 0.4],\n",
              "       [1. , 1. , 0.2],\n",
              "       [1. , 1.7, 0.5],\n",
              "       [1. , 1.9, 0.2],\n",
              "       [1. , 1.6, 0.2],\n",
              "       [1. , 1.6, 0.4],\n",
              "       [1. , 1.5, 0.2],\n",
              "       [1. , 1.4, 0.2],\n",
              "       [1. , 1.6, 0.2],\n",
              "       [1. , 1.6, 0.2],\n",
              "       [1. , 1.5, 0.4],\n",
              "       [1. , 1.5, 0.1],\n",
              "       [1. , 1.4, 0.2],\n",
              "       [1. , 1.5, 0.2],\n",
              "       [1. , 1.2, 0.2],\n",
              "       [1. , 1.3, 0.2],\n",
              "       [1. , 1.4, 0.1],\n",
              "       [1. , 1.3, 0.2],\n",
              "       [1. , 1.5, 0.2],\n",
              "       [1. , 1.3, 0.3],\n",
              "       [1. , 1.3, 0.3],\n",
              "       [1. , 1.3, 0.2],\n",
              "       [1. , 1.6, 0.6],\n",
              "       [1. , 1.9, 0.4],\n",
              "       [1. , 1.4, 0.3],\n",
              "       [1. , 1.6, 0.2],\n",
              "       [1. , 1.4, 0.2],\n",
              "       [1. , 1.5, 0.2],\n",
              "       [1. , 1.4, 0.2],\n",
              "       [1. , 4.7, 1.4],\n",
              "       [1. , 4.5, 1.5],\n",
              "       [1. , 4.9, 1.5],\n",
              "       [1. , 4. , 1.3],\n",
              "       [1. , 4.6, 1.5],\n",
              "       [1. , 4.5, 1.3],\n",
              "       [1. , 4.7, 1.6],\n",
              "       [1. , 3.3, 1. ],\n",
              "       [1. , 4.6, 1.3],\n",
              "       [1. , 3.9, 1.4],\n",
              "       [1. , 3.5, 1. ],\n",
              "       [1. , 4.2, 1.5],\n",
              "       [1. , 4. , 1. ],\n",
              "       [1. , 4.7, 1.4],\n",
              "       [1. , 3.6, 1.3],\n",
              "       [1. , 4.4, 1.4],\n",
              "       [1. , 4.5, 1.5],\n",
              "       [1. , 4.1, 1. ],\n",
              "       [1. , 4.5, 1.5],\n",
              "       [1. , 3.9, 1.1],\n",
              "       [1. , 4.8, 1.8],\n",
              "       [1. , 4. , 1.3],\n",
              "       [1. , 4.9, 1.5],\n",
              "       [1. , 4.7, 1.2],\n",
              "       [1. , 4.3, 1.3],\n",
              "       [1. , 4.4, 1.4],\n",
              "       [1. , 4.8, 1.4],\n",
              "       [1. , 5. , 1.7],\n",
              "       [1. , 4.5, 1.5],\n",
              "       [1. , 3.5, 1. ],\n",
              "       [1. , 3.8, 1.1],\n",
              "       [1. , 3.7, 1. ],\n",
              "       [1. , 3.9, 1.2],\n",
              "       [1. , 5.1, 1.6],\n",
              "       [1. , 4.5, 1.5],\n",
              "       [1. , 4.5, 1.6],\n",
              "       [1. , 4.7, 1.5],\n",
              "       [1. , 4.4, 1.3],\n",
              "       [1. , 4.1, 1.3],\n",
              "       [1. , 4. , 1.3],\n",
              "       [1. , 4.4, 1.2],\n",
              "       [1. , 4.6, 1.4],\n",
              "       [1. , 4. , 1.2],\n",
              "       [1. , 3.3, 1. ],\n",
              "       [1. , 4.2, 1.3],\n",
              "       [1. , 4.2, 1.2],\n",
              "       [1. , 4.2, 1.3],\n",
              "       [1. , 4.3, 1.3],\n",
              "       [1. , 3. , 1.1],\n",
              "       [1. , 4.1, 1.3],\n",
              "       [1. , 6. , 2.5],\n",
              "       [1. , 5.1, 1.9],\n",
              "       [1. , 5.9, 2.1],\n",
              "       [1. , 5.6, 1.8],\n",
              "       [1. , 5.8, 2.2],\n",
              "       [1. , 6.6, 2.1],\n",
              "       [1. , 4.5, 1.7],\n",
              "       [1. , 6.3, 1.8],\n",
              "       [1. , 5.8, 1.8],\n",
              "       [1. , 6.1, 2.5],\n",
              "       [1. , 5.1, 2. ],\n",
              "       [1. , 5.3, 1.9],\n",
              "       [1. , 5.5, 2.1],\n",
              "       [1. , 5. , 2. ],\n",
              "       [1. , 5.1, 2.4],\n",
              "       [1. , 5.3, 2.3],\n",
              "       [1. , 5.5, 1.8],\n",
              "       [1. , 6.7, 2.2],\n",
              "       [1. , 6.9, 2.3],\n",
              "       [1. , 5. , 1.5],\n",
              "       [1. , 5.7, 2.3],\n",
              "       [1. , 4.9, 2. ],\n",
              "       [1. , 6.7, 2. ],\n",
              "       [1. , 4.9, 1.8],\n",
              "       [1. , 5.7, 2.1],\n",
              "       [1. , 6. , 1.8],\n",
              "       [1. , 4.8, 1.8],\n",
              "       [1. , 4.9, 1.8],\n",
              "       [1. , 5.6, 2.1],\n",
              "       [1. , 5.8, 1.6],\n",
              "       [1. , 6.1, 1.9],\n",
              "       [1. , 6.4, 2. ],\n",
              "       [1. , 5.6, 2.2],\n",
              "       [1. , 5.1, 1.5],\n",
              "       [1. , 5.6, 1.4],\n",
              "       [1. , 6.1, 2.3],\n",
              "       [1. , 5.6, 2.4],\n",
              "       [1. , 5.5, 1.8],\n",
              "       [1. , 4.8, 1.8],\n",
              "       [1. , 5.4, 2.1],\n",
              "       [1. , 5.6, 2.4],\n",
              "       [1. , 5.1, 2.3],\n",
              "       [1. , 5.1, 1.9],\n",
              "       [1. , 5.9, 2.3],\n",
              "       [1. , 5.7, 2.5],\n",
              "       [1. , 5.2, 2.3],\n",
              "       [1. , 5. , 1.9],\n",
              "       [1. , 5.2, 2. ],\n",
              "       [1. , 5.4, 2.3],\n",
              "       [1. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과를 일정하게 하기 위해, random seed 배정\n",
        "np.random.seed(1234)"
      ],
      "metadata": {
        "id": "kiYjC0PAjSSz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원래면 sklearn의 train_test_split을 사용하지만, 직접 만들면서 원리 이해하기\n",
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "total_size = len(X_with_bias)\n",
        "\n",
        "test_size = int(total_size * test_ratio)\n",
        "validation_size = int(total_size * validation_ratio)\n",
        "train_size = total_size - test_size - validation_size\n",
        "\n",
        "rnd_indices = np.random.permutation(total_size)    # 150을 무작위로 섞음\n",
        "\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]  # test_size 만큼 남겨둠\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "metadata": {
        "id": "uLhDlgnki6RL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스를 OneHot Vector로 바꾸기\n",
        "def to_one_hot(y):\n",
        "    n_classes = y.max()+1    # 0,1,2 라 max=2 / +1 하면 classes 개수\n",
        "    m = len(y)                     # 총 150개의 라벨들\n",
        "    y_one_hot = np.zeros((m,n_classes))\n",
        "    y_one_hot[np.arange(m),y] = 1   # index의 행중에 y값을 1로 치환\n",
        "    return y_one_hot"
      ],
      "metadata": {
        "id": "GJl6Ct0qjmB4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBW7jr_njsxr",
        "outputId": "bce6dedc-3967-4417-f298-4520601f4c2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 1, 0, 2, 0, 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_one_hot(y_train[:10])   # one hot encoding이 된 것을 확인할 수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjU-fS6Fjvkl",
        "outputId": "8a0ce9a5-f352-490f-c962-f6f6c397430e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 전부를 onehot encoding하기\n",
        "y_train_one_hot = to_one_hot(y_train)\n",
        "y_valid_one_hot = to_one_hot(y_valid)\n",
        "y_test_one_hot = to_one_hot(y_test)"
      ],
      "metadata": {
        "id": "sYb_LNrCj0RW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax 함수 만들기\n",
        "\n",
        "def softmax(logits):\n",
        "    exps = np.exp(logits)\n",
        "    exp_sums = np.sum(exps,axis=1,keepdims=True)   # axis=1   ->  가장 안쪽의 [ ] 안의 성분의 합 / 각 exps들의 합\n",
        "    return exps/exp_sums"
      ],
      "metadata": {
        "id": "u583e5pyj4OB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력과 출력의 갯수 정하기\n",
        "n_inputs = X_train.shape[1]   # (90,3) 인데 1로 인덱싱 ==3\n",
        "n_outputs = len(np.unique(y_train))  # y_train값을 중복되지 않는 값들을 출력  3"
      ],
      "metadata": {
        "id": "-aNsP7sckMnC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 0.01\n",
        "n_iteration = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7 # ε : 입실론     nan값을 피하기 위해 logPi에 추가.\n",
        "\n",
        "Theta = np.random.randn(n_inputs,n_outputs)\n",
        "\n",
        "for i in range(n_iteration):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    loss = -np.mean(np.sum(y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "    error = Y_proba - y_train_one_hot\n",
        "    if i % 500 == 0:\n",
        "        print(i,loss)\n",
        "    gradients = 1/m * X_train.T.dot(error)\n",
        "    Theta = Theta - eta * gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk-DYwBzkfHM",
        "outputId": "29c6216f-8182-439d-a203-0a186e9fc6bd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 4.456626790027361\n",
            "500 0.8657136496506249\n",
            "1000 0.7005808316916647\n",
            "1500 0.6089786295610415\n",
            "2000 0.5508727092472223\n",
            "2500 0.5101260538634483\n",
            "3000 0.47946097080895667\n",
            "3500 0.45518710600148743\n",
            "4000 0.4352445621651113\n",
            "4500 0.41839302935255956\n",
            "5000 0.4038394789494229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 파라미터 확인\n",
        "Theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sH98no5kkv8",
        "outputId": "e02cea08-9684-4122-b5e9-339e25322c65"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.71038557, -0.69054462, -2.30667451],\n",
              "       [-1.01679755,  0.68672499,  0.18399487],\n",
              "       [-0.58705459, -0.84493464,  1.6707505 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#검증 세트에 대한 정확도 확인\n",
        "logits = X_valid.dot(Theta)\n",
        "y_proba = softmax(logits)\n",
        "y_predict = np.argmax(y_proba, axis=1)\n",
        "\n",
        "accuracy = np.mean(y_predict == y_valid)\n",
        "accuracy\n",
        "# 모델이 매우 잘 작동하는 것으로 확인됨\n",
        "# L2규제를 추가해보자"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udtQgA9PknmP",
        "outputId": "8476edf8-44c6-41d4-8e5c-32bb846fb03f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 0.1\n",
        "n_iteration = 5001\n",
        "m = len(X_train)\n",
        "epilson = 1e-7\n",
        "alpha = 0.1  # 규제 파라미터\n",
        "\n",
        "Theta = np.random.randn(n_inputs,n_outputs)\n",
        "\n",
        "for i in range(n_iteration):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    entropy_loss = -np.mean(np.sum(y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = entropy_loss + alpha * l2_loss\n",
        "    error = Y_proba - y_train_one_hot\n",
        "    if i % 500 == 0:\n",
        "        print(i,loss)\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1,n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVGxxX6Pkydm",
        "outputId": "0a4ef955-3f56-4e55-c523-8ca93ba11964"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 5.0146603613986365\n",
            "500 0.5556465182243013\n",
            "1000 0.5143069386328513\n",
            "1500 0.5031760730912317\n",
            "2000 0.4989606825819879\n",
            "2500 0.49720595327787365\n",
            "3000 0.49644208341157703\n",
            "3500 0.4961010127631866\n",
            "4000 0.4959463456620506\n",
            "4500 0.49587551321192525\n",
            "5000 0.49584286509919806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# l2 패널티 때문에 손실이 더 커보인다. 모델이 더 잘 작동하는지 확인해보자\n",
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba,axis=1)\n",
        "\n",
        "acc = np.mean(y_predict == y_valid)\n",
        "acc\n",
        "# 더 성능이 좋은 모델이 되었다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQN5UyxPk34N",
        "outputId": "3467b111-1121-4764-b8c4-696af0c3a8c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기 종료 추가\n",
        "eta = 0.1\n",
        "m = len(X_train)\n",
        "iteration= 5001\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1\n",
        "best_loss = np.infty\n",
        "\n",
        "Theta = np.random.randn(n_inputs,n_outputs)\n",
        "\n",
        "for i in range(iteration):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    entropy_loss = -np.mean(np.sum(y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = entropy_loss + alpha * l2_loss\n",
        "    error = Y_proba - y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[(np.zeros([1,n_outputs]),alpha * Theta[1:])]\n",
        "    Theta = Theta - eta * gradients\n",
        "\n",
        "    logits = X_valid.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    xentropy_loss = -np.mean(np.sum(y_valid_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = xentropy_loss + alpha * l2_loss\n",
        "    if iteration % 500 == 0:\n",
        "        print(i,loss)\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:\n",
        "        print(i-1, best_loss)\n",
        "        print(i,loss,\"Early Stopping!\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urOkKbT1k9Mm",
        "outputId": "85da684d-06d6-4e43-91c5-756c33cc0e4d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1512 0.4980710619819865\n",
            "1513 0.4980710675462317 Early Stopping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqpZQah-lBbc",
        "outputId": "7eedc107-c026-4214-ba80-1170bc18dab4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}